---
description: "Always apply. Non-negotiable Boomi extraction rules for this repo."
alwaysApply: true
---

# BOOMI PROCESS EXTRACTION RULES

**Purpose:** Extract true execution sequence from ANY Boomi process  
**Scope:** Universal - Applicable to ALL Boomi process types  
**Version:** 2.0 - Prescriptive Extraction Guide

---

## üö® CRITICAL PRINCIPLES (NEVER VIOLATE)

**üõë EXPLICIT ENFORCEMENT: These principles are NON-NEGOTIABLE. Violation will result in incorrect extraction.**

1. **Data dependencies ALWAYS override visual layout** - If OperationA writes Property_X and OperationB reads Property_X, OperationA MUST execute before OperationB, regardless of dragpoint order.
   - **ENFORCEMENT**: You MUST check data dependencies FIRST before following dragpoints
   - **VALIDATION**: All property reads must happen after property writes - verify this in Phase 1 document

2. **Check-before-create pattern is MANDATORY** - Existence checks (GetEntity ‚Üí Decision ‚Üí Create) execute BEFORE creation operations. If entity exists, process exits early.
   - **ENFORCEMENT**: Check operations MUST execute before create operations - verify in execution order

3. **Topological sort is MANDATORY for branch paths** - If branch paths have data dependencies, you MUST build dependency graph and sort paths before determining execution order.
   - **ENFORCEMENT**: You CANNOT assume branches are parallel - you MUST analyze dependencies first
   - **VALIDATION**: Branch analysis section in Phase 1 MUST show dependency graph and topological sort

4. **Decision analysis is BLOCKING** - You CANNOT create sequence diagram until ALL decision shapes are analyzed and both TRUE/FALSE paths traced to termination.
   - **ENFORCEMENT**: Sequence diagram section CANNOT be created until decision analysis section exists in Phase 1
   - **VALIDATION**: All decision TRUE/FALSE paths must be traced and documented

5. **Early exits change entire flow** - If decision path leads to Return Documents, that is an early exit and must be documented in sequence.
   - **ENFORCEMENT**: Early exits MUST be marked [EARLY EXIT] in sequence diagram

6. **DO NOT ASSUME - YOU MUST ANALYZE** - Never assume branch classification, execution order, or dependencies. Always extract from JSON and show proof.
   - **ENFORCEMENT**: All analysis must be documented in Phase 1 with proof (JSON references, dependency graphs)
   - **VALIDATION**: If you cannot show proof of analysis ‚Üí You assumed ‚Üí WRONG

7. **üö® CRITICAL: ALL API CALLS ARE SEQUENTIAL** - There is NO concept of parallel API calls in Azure Functions migration. All API calls (REST, SOAP, HTTP operations) MUST execute sequentially, one after another.
   - **ENFORCEMENT**: If a branch contains API calls, it is ALWAYS SEQUENTIAL, regardless of data dependencies
   - **ENFORCEMENT**: Branch paths with API calls MUST be ordered sequentially (Path 1 ‚Üí Path 2 ‚Üí Path 3)
   - **VALIDATION**: All branch classifications involving API calls must be marked as SEQUENTIAL
   - **RULE**: Even if branch paths have no data dependencies, if they contain API calls, they execute sequentially

8. **Map field names are AUTHORITATIVE for SOAP envelopes** - Profiles define schema, maps show actual usage. When profile and map field names differ, ALWAYS use map field names.
   - **ENFORCEMENT**: You MUST analyze maps (Step 1d) before creating SOAP envelopes
   - **VALIDATION**: All SOAP envelopes must use field names from maps, not profiles
   - **EXAMPLE:** Profile says "BDET_FKEY_CAT_SEQ", map uses "CategoryId" ‚Üí Use "CategoryId"

---

## üìã MANDATORY EXTRACTION WORKFLOW

### STEP 1: Load JSON Files and Build Lookup Tables

```
FOR EACH file in process directory:
  IF file matches pattern: process_*.json ‚Üí Main process
  IF file matches pattern: subprocess_*.json ‚Üí Subprocess
  IF file matches pattern: operation_*.json ‚Üí Operation
  IF file matches pattern: profile_*.json ‚Üí Profile
  IF file matches pattern: map_*.json ‚Üí Map

BUILD:
  shapes_by_id = {}  # { "shape1": shape_object, "shape2": shape_object }
  operations_by_id = {}  # { "operation_guid": operation_object }
  profiles_by_id = {}  # { "profile_guid": profile_object }
```

### STEP 1a: Input Structure Analysis (MANDATORY - CONTRACT VERIFICATION)

**üõë EXPLICIT ENFORCEMENT - CRITICAL STEP:**

**YOU CANNOT PROCEED TO PHASE 2** until this step is complete and documented.

**üö® CRITICAL:** This step ensures DTOs exactly match Boomi process contracts. **NEVER SKIP.**

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Input Structure Analysis (Step 1a)
```

This section MUST be created BEFORE proceeding to Phase 2.

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Input Structure Analysis (Step 1a)" ‚Üí Step 1a NOT complete ‚Üí **CANNOT PROCEED TO PHASE 2**

```
# Step 1: Identify Entry Point Operation
entry_operation = find_entry_operation(process_json)  # Usually "start" shape with connectoraction
entry_operation_id = entry_operation.connectoraction.operationId
entry_operation_json = operations_by_id[entry_operation_id]

# Step 2: Extract Request Profile
IF entry_operation_json.type == "connector-action" AND entry_operation_json.subType == "wss":
  request_profile_id = entry_operation_json.configuration.WebServicesServerListenAction.requestProfile
ELSE IF entry_operation_json.type == "connector-action" AND entry_operation_json.subType == "http":
  request_profile_id = entry_operation_json.configuration.HttpRequestAction.requestProfile
ELSE:
  # Check other operation types (ftp, database, etc.)
  request_profile_id = extract_request_profile_id(entry_operation_json)

request_profile = profiles_by_id[request_profile_id]

# Step 3: Analyze Profile Structure
IF request_profile.type == "profile.json":
  input_structure = analyze_json_profile_structure(request_profile)
ELSE IF request_profile.type == "profile.xml":
  input_structure = analyze_xml_profile_structure(request_profile)
ELSE:
  ERROR: Unknown profile type

FUNCTION analyze_json_profile_structure(profile):
  structure = {
    "rootElement": None,
    "isArray": False,
    "arrayCardinality": {"minOccurs": 0, "maxOccurs": 1},
    "fields": [],
    "nestedStructures": [],
    "fieldPaths": {}  # Full paths like "Root/Object/entityArray/Array/ArrayElement1/Object/fieldName"
  }
  
  # Extract root element
  root = profile.JSONProfile.DataElements[0].JSONRootValue
  structure.rootElement = root.name  # Usually "Root"
  
  # Traverse JSON structure
  traverse_json_structure(root, structure, current_path="Root")
  
  RETURN structure

FUNCTION traverse_json_structure(element, structure, current_path=""):
  # Check for JSONObject
  IF element.JSONObject exists:
    FOR EACH entry in element.JSONObject.JSONObjectEntry[]:
      field_name = entry.name
      field_path = f"{current_path}/Object/{field_name}"
      
      # Check if this field is an array
      IF entry.JSONArray exists:
        array_info = {
          "name": field_name,
          "path": field_path,
          "isArray": True,
          "elementType": entry.JSONArray.elementType,  # "repeating" or "single"
          "minOccurs": entry.JSONArray.JSONArrayElement[0].minOccurs,
          "maxOccurs": entry.JSONArray.JSONArrayElement[0].maxOccurs,
          "arrayElementName": entry.JSONArray.JSONArrayElement[0].name
        }
        structure.isArray = True
        structure.arrayCardinality = {
          "minOccurs": array_info["minOccurs"],
          "maxOccurs": array_info["maxOccurs"]
        }
        structure.nestedStructures.append(array_info)
        
        # Traverse array element structure
        array_element = entry.JSONArray.JSONArrayElement[0]
        array_element_path = f"{field_path}/Array/{array_info['arrayElementName']}"
        traverse_json_structure(array_element, structure, array_element_path)
      ELSE:
        # Regular field
        field_info = {
          "name": field_name,
          "path": field_path,
          "dataType": entry.dataType,
          "isRequired": entry.allowEmpty == "false",
          "isMappable": entry.isMappable == "true"
        }
        structure.fields.append(field_info)
        structure.fieldPaths[field_path] = field_info
        
        # Check for nested JSONObject
        IF entry.JSONObject exists:
          traverse_json_structure(entry, structure, field_path)

FUNCTION analyze_xml_profile_structure(profile):
  # Similar traversal for XML profiles
  structure = {
    "rootElement": None,
    "isArray": False,
    "arrayCardinality": {"minOccurs": 0, "maxOccurs": 1},
    "fields": [],
    "nestedStructures": [],
    "fieldPaths": {}
  }
  
  # Extract root element from XMLProfile
  root = profile.XMLProfile.DataElements[0].XMLRootValue
  structure.rootElement = root.name
  
  # Traverse XML structure (similar to JSON but with XML-specific elements)
  traverse_xml_structure(root, structure, current_path=root.name)
  
  RETURN structure

# Step 4: Document Input Structure
input_structure_documentation = {
  "profileId": request_profile_id,
  "profileName": request_profile.name,
  "profileType": request_profile.type,
  "structure": input_structure,
  "inputType": entry_operation_json.configuration.WebServicesServerListenAction.inputType,  # "singlejson", "document", etc.
  "documentProcessingBehavior": determine_document_processing_behavior(input_structure, entry_operation_json)
}

FUNCTION determine_document_processing_behavior(structure, operation):
  # If inputType is "singlejson" and structure has array:
  IF operation.inputType == "singlejson" AND structure.isArray:
    RETURN {
      "behavior": "document_splitting",
      "description": "Boomi automatically splits array into separate documents. Each array element triggers separate process execution.",
      "executionPattern": "one_per_element",
      "sessionManagement": "one_session_per_execution"
    }
  ELSE IF operation.inputType == "document":
    RETURN {
      "behavior": "batch_processing",
      "description": "Boomi processes entire document as single execution.",
      "executionPattern": "single_execution",
      "sessionManagement": "one_session_per_execution"
    }
  ELSE:
    RETURN {
      "behavior": "single_document",
      "description": "Boomi processes single document.",
      "executionPattern": "single_execution",
      "sessionManagement": "one_session_per_execution"
    }

# Step 5: Extract ALL Fields (Including Nested)
all_fields = []
extract_all_fields_recursive(input_structure, all_fields, parent_path="")

FUNCTION extract_all_fields_recursive(structure, fields_list, parent_path):
  FOR EACH field in structure.fields:
    full_path = f"{parent_path}/{field.name}" if parent_path else field.name
    fields_list.append({
      "name": field.name,
      "fullPath": full_path,
      "dataType": field.dataType,
      "isRequired": field.isRequired,
      "isMappable": field.isMappable,
      "parentPath": parent_path
    })
  
  FOR EACH nested in structure.nestedStructures:
    nested_path = f"{parent_path}/{nested.name}" if parent_path else nested.name
    extract_all_fields_recursive(nested, fields_list, nested_path)

# Step 6: Generate Field Mapping Table
field_mapping_table = []
FOR EACH field in all_fields:
  field_mapping_table.append({
    "boomiFieldPath": field.fullPath,
    "boomiFieldName": field.name,
    "dataType": field.dataType,
    "isRequired": field.isRequired,
    "azureDTOProperty": generate_azure_property_name(field.name),  # PascalCase conversion
    "notes": determine_field_usage(field, process_json)
  })

FUNCTION generate_azure_property_name(boomi_name):
  # Convert Boomi field name to C# property name
  # Examples:
  # "fieldName" ‚Üí "FieldName"
  # "entityCode" ‚Üí "EntityCode"
  # "nestedObject" ‚Üí "NestedObject"
  parts = boomi_name.split(/(?=[A-Z])/)  # Split on camelCase boundaries
  return "".join([part.capitalize() for part in parts])

FUNCTION determine_field_usage(field, process_json):
  # Search process for usage of this field
  usage = []
  FOR EACH shape in process_json.shapes[]:
    IF field appears in shape configuration:
      usage.append(f"Used in {shape.shapetype} {shape.shapeId}")
  RETURN "; ".join(usage) if usage else "Not found in process flow"

OUTPUT: Complete input structure analysis with field mapping table
```

**CRITICAL RULES:**
1. **Input structure analysis is MANDATORY** - Must be completed before Phase 2
2. **Array detection is CRITICAL** - If array found, Process Layer DTO MUST accept List<T>
3. **Field mapping is EXACT** - Every Boomi field MUST have corresponding Azure DTO property
4. **Nested structures MUST be analyzed** - All nested objects/arrays must be extracted
5. **Cardinality matters** - minOccurs/maxOccurs determine if field is optional/required
6. **Document processing behavior MUST be documented** - How Boomi processes input affects Azure implementation

**Validation Checklist:**
- [ ] Request profile identified from entry operation
- [ ] Profile structure analyzed (JSON or XML)
- [ ] Array vs single object detected
- [ ] Array cardinality documented (minOccurs, maxOccurs)
- [ ] ALL fields extracted (including nested)
- [ ] Field paths documented (full Boomi paths)
- [ ] Field mapping table generated (Boomi ‚Üí Azure DTO)
- [ ] Document processing behavior determined
- [ ] Input structure documented in Phase 1 document

### STEP 1b: Response Structure Analysis (MANDATORY - CONTRACT VERIFICATION)

**üõë EXPLICIT ENFORCEMENT - CRITICAL STEP:**

**YOU CANNOT PROCEED TO PHASE 2** until this step is complete and documented.

**üö® CRITICAL:** Analyze response profile to ensure response DTOs match exactly.

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Response Structure Analysis (Step 1b)
```

This section MUST be created BEFORE proceeding to Phase 2.

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Response Structure Analysis (Step 1b)" ‚Üí Step 1b NOT complete ‚Üí **CANNOT PROCEED TO PHASE 2**

```
# Step 1: Identify Response Profile
IF entry_operation_json.type == "connector-action" AND entry_operation_json.subType == "wss":
  response_profile_id = entry_operation_json.configuration.WebServicesServerListenAction.responseProfile
ELSE:
  response_profile_id = extract_response_profile_id(entry_operation_json)

response_profile = profiles_by_id[response_profile_id]

# Step 2: Analyze Response Structure (same as input structure analysis)
response_structure = analyze_profile_structure(response_profile)

# Step 3: Generate Response Field Mapping Table
response_field_mapping = generate_field_mapping_table(response_structure)

OUTPUT: Complete response structure analysis with field mapping table
```

### STEP 1c: Analyze Operation Response Structures (MANDATORY)

**üõë EXPLICIT ENFORCEMENT - CRITICAL STEP:**

**YOU CANNOT PROCEED TO STEP 7 (Decision Analysis)** until this step is complete and documented.

**üö® CRITICAL:** This step identifies what data operations produce, which is essential for:
- Understanding if decisions check RESPONSE data vs INPUT data
- Verifying actual execution order (operations that produce data must execute before operations that consume it)
- Identifying business logic flow

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Operation Response Analysis (Step 1c)
```

This section MUST be created BEFORE proceeding to Step 7 or Step 9.

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Operation Response Analysis (Step 1c)" ‚Üí Step 1c NOT complete ‚Üí **CANNOT PROCEED TO STEP 7**

```
operation_response_analysis = []

FOR EACH operation in operations_by_id.values():
  IF operation has responseProfile:
    response_profile_id = operation.responseProfile
    response_profile_json = profiles_by_id[response_profile_id]
    
    # Analyze response structure
    response_structure = analyze_profile_structure(response_profile_json)
    
    # Identify fields that might be extracted (via documentproperties shapes)
    extracted_fields = []
    FOR EACH shape in shapes_by_id.values():
      IF shape.shapetype == "documentproperties":
        FOR EACH assignment in shape.documentproperties.propertyassignments[]:
          FOR EACH sourcevalue in assignment.sourcevalues[]:
            IF sourcevalue.valueType == "profile":
              IF sourcevalue.profileelement.profileId == response_profile_id:
                # This field is extracted from operation response
                field_name = sourcevalue.profileelement.elementName
                extracted_fields.append({
                  "field": field_name,
                  "extractedBy": shape.shapeId,
                  "writtenToProperty": assignment.propertyId
                })
    
    # Identify operations/decisions that use response data
    consumers = []
    FOR EACH extracted_field in extracted_fields:
      property_name = extracted_field["writtenToProperty"]
      # Find shapes that read this property
      IF property_name in property_reads:
        consumers.extend(property_reads[property_name])
    
    operation_response_analysis.append({
      "operationId": operation.operationId,
      "operationName": operation.name,
      "responseProfileId": response_profile_id,
      "responseStructure": response_structure,
      "extractedFields": extracted_fields,
      "consumers": consumers  # Operations/decisions that use response data
    })

OUTPUT: Complete analysis of all operation responses, extracted fields, and consumers
```

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "Operation Response Analysis (Step 1c)":

1. **Operation Response Inventory:**
   - For each operation with response profile: Operation ID, name, response profile ID
   - Response structure (fields, types, cardinality)

2. **Extracted Fields:**
   - For each operation: List of fields extracted from response (via documentproperties shapes)
   - Which shape extracts each field
   - Which process property each field is written to

3. **Data Consumers:**
   - For each extracted field: List of operations/decisions that use the data
   - **PROOF**: Show property dependency chain (Operation ‚Üí Extract ‚Üí Write Property ‚Üí Read Property ‚Üí Consumer)

4. **Business Logic Implications:**
   - For each operation: What operations MUST execute after it (because they consume its response data)
   - For each decision: Does it check response data? If yes, which operation produces that data?

**EXAMPLE:**
```
OperationA:
  - Response Profile: [profile-guid]
  - Extracted Field: EntityId (extracted by shapeX, written to process.Property_EntityId)
  - Consumers: shapeY (OperationB) reads process.Property_EntityId
  - Business Logic: OperationA MUST execute BEFORE OperationB
```

**IF OPERATION RESPONSE ANALYSIS IS MISSING ‚Üí Step 1c NOT complete ‚Üí CANNOT PROCEED TO STEP 7**

### STEP 1d: Map Analysis (MANDATORY - FIELD NAME VERIFICATION)

**üõë EXPLICIT ENFORCEMENT - CRITICAL STEP:**

**YOU CANNOT PROCEED TO PHASE 2 (SOAP ENVELOPE CREATION)** until this step is complete and documented.

**üö® CRITICAL:** This step identifies ACTUAL field names used in SOAP requests, which may differ from profile field names.

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Map Analysis (Step 1d)
```
This section MUST be created BEFORE proceeding to Phase 2.
**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Map Analysis (Step 1d)" ‚Üí Step 1d NOT complete ‚Üí **CANNOT PROCEED TO PHASE 2**

```
map_analysis = []

# Step 1: Load all map files
maps_by_id = {}
FOR EACH file in directory:
  IF file matches pattern: map_*.json:
    map_json = load_json(file)
    map_id = map_json.componentId
    maps_by_id[map_id] = map_json

# Step 2: Identify SOAP request maps
soap_request_maps = []
FOR EACH map in maps_by_id.values():
  to_profile_id = map.Map.toProfile

  # Check if target profile is used as request profile for SOAP operation
  FOR EACH operation in operations_by_id.values():
    IF operation.requestProfile == to_profile_id:
      IF operation.subType in ["http", "soap", "wss"]:
        soap_request_maps.append({
          "mapId": map.componentId,
          "mapName": map.name,
          "operationId": operation.componentId,
          "operationName": operation.name,
          "fromProfile": map.Map.fromProfile,
          "toProfile": to_profile_id
        })
        BREAK

# Step 3: Extract field mappings from each SOAP request map
FOR EACH soap_map in soap_request_maps:
  map_json = maps_by_id[soap_map.mapId]
  field_mappings = []

  FOR EACH mapping in map_json.Map.Mappings.Mapping[]:
    # Extract target field name (SOAP request field)
    target_path = mapping.toNamePath
    # Example: "Envelope/Body/CreateBreakdownTask/breakdownTaskDto/CategoryId"
    target_parts = target_path.split("/")
    target_field_name = target_parts[-1]  # "CategoryId"
    target_element = target_parts[-2]  # "breakdownTaskDto"
    operation_element = target_parts[2]  # "CreateBreakdownTask"

    # Extract source information
    source_info = extract_source_info(mapping, map_json)

    field_mappings.append({
      "sourceField": source_info.field_name,
      "sourceType": source_info.type,
      "targetField": target_field_name,
      "targetElement": target_element,
      "targetPath": target_path,
      "operationElement": operation_element
    })

  soap_map.field_mappings = field_mappings
  soap_map.operationElement = operation_element
  soap_map.dtoElement = target_element

# Step 4: Compare with profile field names
FOR EACH soap_map in soap_request_maps:
  profile_id = soap_map.toProfile
  profile_json = profiles_by_id[profile_id]

  discrepancies = []

  FOR EACH field_mapping in soap_map.field_mappings:
    target_field = field_mapping.targetField

    # Find this field in profile
    profile_field = find_field_in_profile(profile_json, target_field)

    IF profile_field is None:
      # Field in map but not in profile - unusual but possible
      discrepancies.append({
        "mapField": target_field,
        "profileField": "NOT_FOUND",
        "issue": "Map uses field not in profile"
      })
    ELSE:
      # Check if field names differ
      IF profile_field.technical_name != target_field:
        discrepancies.append({
          "mapField": target_field,
          "profileField": profile_field.technical_name,
          "issue": "Profile uses technical name, map uses simplified name"
        })

  soap_map.discrepancies = discrepancies

# Step 5: Analyze scripting functions
FOR EACH soap_map in soap_request_maps:
  map_json = maps_by_id[soap_map.mapId]

  IF map_json.Map.Functions exists:
    scripting_functions = []

    FOR EACH function_step in map_json.Map.Functions.FunctionStep[]:
      IF function_step.type == "Scripting":
        scripting_functions.append({
          "functionKey": function_step.key,
          "inputs": extract_function_inputs(function_step),
          "outputs": extract_function_outputs(function_step),
          "script": function_step.Configuration.Scripting.ScriptToExecute,
          "language": function_step.Configuration.Scripting.language
        })

    soap_map.scripting_functions = scripting_functions

# Step 6: Extract namespace prefixes from message shapes
FOR EACH soap_map in soap_request_maps:
  operation_id = soap_map.operationId

  # Find message shape that builds SOAP request for this operation
  message_shape = find_message_shape_for_operation(operation_id, process_json)

  IF message_shape exists:
    # Extract SOAP envelope from message shape
    soap_envelope = message_shape.message.msgTxt

    # Extract namespace declarations
    namespaces = extract_namespace_declarations(soap_envelope)
    # Example: {"fsi1": "http://schemas.datacontract.org/2004/07/Fsi.Concept.Contracts.Entities.ServiceModel"}

    # Extract field namespace prefixes
    field_prefixes = extract_field_prefixes(soap_envelope)
    # Example: {"BarCode": "fsi1", "IN_DESCRIPTION": "fsi2"}

    soap_map.namespaces = namespaces
    soap_map.field_prefixes = field_prefixes

  map_analysis.append(soap_map)

FUNCTION check_if_soap_request_map(profile_id, operations):
  """
  Check if profile is used as request profile for any SOAP operation
  """
  FOR EACH operation in operations.values():
    IF operation.requestProfile == profile_id:
      IF operation.subType in ["http", "soap", "wss"]:
        RETURN True
  RETURN False

FUNCTION extract_field_name_from_path(name_path):
  """
  Extract field name from path like "Envelope/Body/CreateBreakdownTask/breakdownTaskDto/CategoryId"
  Returns: "CategoryId"
  """
  parts = name_path.split("/")
  RETURN parts[-1]  # Last part is field name

FUNCTION extract_source_info(mapping, map_json):
  """
  Extract source field information from mapping
  """
  IF mapping.fromType == "profile":
    # Direct field mapping from input profile
    source_path = mapping.fromNamePath
    source_parts = source_path.split("/")
    field_name = source_parts[-1]
    RETURN {
      "field_name": field_name,
      "type": "profile",
      "path": source_path
    }

  ELIF mapping.fromType == "function":
    # Mapping from function result (process property, scripting, etc.)
    function_key = mapping.fromFunction
    function_step = find_function_step(map_json, function_key)

    IF function_step.type == "PropertyGet":
      # Process property
      property_name = function_step.Inputs.Input[0].default
      RETURN {
        "field_name": property_name,
        "type": "process_property",
        "property": property_name
      }

    ELIF function_step.type == "DefinedProcessPropertyGet":
      # Defined process property
      property_name = function_step.Configuration.DefinedProcessProperty.propertyName
      RETURN {
        "field_name": property_name,
        "type": "defined_property",
        "property": property_name
      }

    ELIF function_step.type == "Scripting":
      # Scripting function
      output_name = function_step.Outputs.Output.name
      RETURN {
        "field_name": output_name,
        "type": "scripting",
        "script": function_step.Configuration.Scripting.ScriptToExecute
      }

    ELSE:
      RETURN {
        "field_name": "FUNCTION_RESULT",
        "type": function_step.type
      }

  ELIF mapping.fromType == "static":
    # Static value
    RETURN {
      "field_name": "STATIC_VALUE",
      "type": "static"
    }

  ELSE:
    RETURN {
      "field_name": "UNKNOWN",
      "type": mapping.fromType
    }

OUTPUT: Complete map analysis showing actual SOAP field names used
```

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "Map Analysis (Step 1d)":

1. **Map Inventory:**
   - For each map: Map ID, name, source profile, target profile
   - Identify which maps are SOAP request maps

2. **SOAP Request Field Mappings:**
   - For each SOAP request map: Complete list of field mappings
   - Source field (input) ‚Üí Target field (SOAP request)
   - **CRITICAL:** Target field name is the ACTUAL field name used in SOAP request

3. **Element Names (CRITICAL):**
   - For each SOAP operation: Document the element name used (dto, breakdownTaskDto, locationDto, etc.)
   - **RULE:** Element names MUST match exactly in SOAP envelopes. Do NOT assume generic "dto" for all operations.

4. **Namespace Prefixes (CRITICAL):**
   - For each SOAP operation: Document namespace declarations and field prefixes
   - **RULE:** Namespace prefixes MUST match Boomi message shapes. Check message shape SOAP envelope for exact namespace declarations and field prefixes.

5. **Profile vs Map Comparison:**
   - For each operation: Compare profile field names vs map field names
   - **PROOF:** Show where profile says "BDET_FKEY_CAT_SEQ" but map uses "CategoryId"
   - Document ALL discrepancies

6. **Field Name Authority:**
   - **RULE:** Map field names are AUTHORITATIVE for SOAP envelopes
   - **RULE:** Profile field names are for schema reference only
   - **CRITICAL:** ALWAYS use map field names when creating SOAP envelopes

7. **Scripting Functions:**
   - For each scripting function: Document inputs, outputs, and script logic
   - **CRITICAL:** Date formatting, concatenation, and other transformations must be replicated

**IF MAP ANALYSIS IS MISSING ‚Üí Step 1d NOT complete ‚Üí CANNOT PROCEED TO PHASE 2**

**EXAMPLE DOCUMENTATION:**

### STEP 1e: Extract HTTP Status Codes and Return Path Responses (MANDATORY)

**üõë EXPLICIT ENFORCEMENT - CRITICAL STEP:**

**YOU CANNOT PROCEED TO PHASE 2** until this step is complete and documented.

**üö® CRITICAL:** This step extracts HTTP status codes for return paths and documents response JSON for each return statement to ensure proper error handling and response mapping in Azure Functions.

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## HTTP Status Codes and Return Path Responses (Step 1e)
```
This section MUST be created BEFORE proceeding to Phase 2.

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "HTTP Status Codes and Return Path Responses (Step 1e)" ‚Üí Step 1e NOT complete ‚Üí **CANNOT PROCEED TO PHASE 2**

```
return_path_analysis = []

# Step 1: Identify all return paths (Return Documents shapes)
FOR EACH shape in shapes_by_id.values():
  IF shape.shapetype == "returndocuments":
    # Extract return label
    return_label = shape.returndocuments.label
    
    # Step 2: Trace path to this return to identify conditions
    path_to_return = trace_path_to_return(shape.shapeId)
    
    # Step 3: Identify decision conditions that lead to this return
    decision_conditions = []
    FOR EACH decision_shape in path_to_return:
      IF decision_shape.shapetype == "decision":
        decision_conditions.append({
          "decisionId": decision_shape.shapeId,
          "condition": extract_decision_condition(decision_shape),
          "path": "TRUE" or "FALSE"  # Which path leads to this return
        })
    
    # Step 4: Extract HTTP status code (if specified in process properties or defined parameters)
    http_status_code = extract_http_status_code(shape, path_to_return)
    # Check for:
    # - Defined process property with HTTP status code
    # - Process property set before return
    # - Default: 200 for success, 400 for validation errors, 500 for server errors
    
    # Step 5: Extract response profile for this return path
    response_profile_id = extract_response_profile_for_return(shape, entry_operation)
    response_profile = profiles_by_id.get(response_profile_id)
    
    # Step 6: Determine populated fields for this return path
    populated_fields = []
    IF response_profile:
      # Check which fields are populated based on path to return
      FOR EACH field in response_profile.fields:
        field_populated = check_if_field_populated(field, path_to_return, property_writes)
        IF field_populated:
          populated_fields.append({
            "fieldName": field.name,
            "fieldPath": field.path,
            "source": field_populated.source,  # "operation_response", "process_property", "input_field"
            "populatedBy": field_populated.populated_by  # Which operation/shape populates it
          })
    
    # Step 7: Generate response JSON example
    response_json_example = generate_response_json_example(response_profile, populated_fields)
    
    return_path_analysis.append({
      "returnLabel": return_label,
      "returnShapeId": shape.shapeId,
      "pathToReturn": path_to_return,
      "decisionConditions": decision_conditions,
      "httpStatusCode": http_status_code,
      "responseProfileId": response_profile_id,
      "populatedFields": populated_fields,
      "responseJsonExample": response_json_example,
      "errorCode": extract_error_code_if_error(path_to_return),  # If this is an error return
      "successCode": extract_success_code_if_success(path_to_return)  # If this is a success return
    })

# Step 8: Extract HTTP status codes for downstream operations
downstream_http_codes = []
FOR EACH operation in operations_by_id.values():
  IF operation.subType in ["http", "soap", "rest", "wss"]:
    # Extract expected HTTP status codes from operation configuration
    expected_status_codes = extract_expected_status_codes(operation)
    
    # Extract error handling (what happens on non-200 responses)
    error_handling = extract_error_handling(operation, shapes_by_id)
    
    downstream_http_codes.append({
      "operationId": operation.operationId,
      "operationName": operation.name,
      "expectedStatusCodes": expected_status_codes,  # e.g., [200, 201]
      "errorStatusCodes": error_handling.error_codes,  # e.g., [400, 404, 500]
      "errorHandling": error_handling.handling_strategy  # "throw_exception", "return_error", "retry"
    })

FUNCTION extract_http_status_code(return_shape, path_to_return):
  """
  Extract HTTP status code for return path
  """
  # Check for defined process property with HTTP status
  FOR EACH shape in path_to_return:
    IF shape.shapetype == "documentproperties":
      FOR EACH assignment in shape.documentproperties.propertyassignments[]:
        IF assignment.propertyId contains "HTTP_STATUS" or assignment.propertyId contains "STATUS_CODE":
          # Try to extract value
          status_code = extract_property_value(assignment)
          IF status_code:
            RETURN int(status_code)
  
  # Check decision conditions to infer status code
  FOR EACH decision in path_to_return:
    IF decision.shapetype == "decision":
      # If decision checks for errors ‚Üí likely 400 or 500
      IF decision.decision.comparison checks error condition:
        RETURN 400  # Validation error
      # If decision checks for not found ‚Üí likely 404
      IF decision.decision.comparison checks "not found" or "empty":
        RETURN 404  # Not found
  
  # Default based on return label
  IF return_shape.returndocuments.label contains "Error" or "Failure":
    RETURN 400  # Bad request
  ELIF return_shape.returndocuments.label contains "Success":
    RETURN 200  # Success
  ELSE:
    RETURN 200  # Default success

FUNCTION check_if_field_populated(field, path_to_return, property_writes):
  """
  Check if response field is populated based on operations in path
  """
  # Check if any operation in path writes this field
  FOR EACH shape in path_to_return:
    IF shape.shapetype == "connectoraction":
      operation = operations_by_id[shape.connectoraction.operationId]
      IF operation.responseProfile:
        # Check if field exists in operation response
        IF field.name in operation.responseProfile.fields:
          RETURN {
            "populated": True,
            "source": "operation_response",
            "populated_by": operation.name
          }
  
  # Check if field is written to process property
  field_property = f"process.Property_{field.name}"
  IF field_property in property_writes:
    RETURN {
      "populated": True,
      "source": "process_property",
      "populated_by": property_writes[field_property]
    }
  
  # Check if field comes from input
  IF field.name in entry_operation.requestProfile.fields:
    RETURN {
      "populated": True,
      "source": "input_field",
      "populated_by": "request"
    }
  
  RETURN {
    "populated": False,
    "source": None,
    "populated_by": None
  }

FUNCTION generate_response_json_example(response_profile, populated_fields):
  """
  Generate example response JSON showing only populated fields
  """
  json_structure = {}
  
  FOR EACH field in populated_fields:
    # Build nested structure based on field path
    path_parts = field.fieldPath.split("/")
    current = json_structure
    
    FOR EACH part in path_parts[:-1]:
      IF part not in current:
        current[part] = {}
      current = current[part]
    
    # Add field with example value
    current[field.fieldName] = generate_example_value(field)
  
  RETURN json_structure

OUTPUT: Complete analysis of HTTP status codes and response JSON for all return paths
```

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "HTTP Status Codes and Return Path Responses (Step 1e)":

1. **Return Path Inventory:**
   - For each Return Documents shape: Return label, shape ID, path to return
   - Decision conditions that lead to each return
   - HTTP status code for each return path

2. **Response JSON for Each Return Path:**
   - For each return path: List of populated fields
   - Source of each field (operation response, process property, input field)
   - Example response JSON showing populated fields only

3. **HTTP Status Codes:**
   - Process Layer return paths: HTTP status code for each return
   - Downstream operations: Expected status codes (success) and error status codes

4. **Error/Success Codes:**
   - For error returns: Error code (if specified)
   - For success returns: Success code (if specified)

**IF HTTP STATUS CODES AND RETURN PATH RESPONSES NOT DOCUMENTED ‚Üí Step 1e NOT complete ‚Üí CANNOT PROCEED TO PHASE 2**

**EXAMPLE DOCUMENTATION:**
```markdown
## Map Analysis (Step 1d)

### SOAP Request Maps Inventory

| Map ID | Map Name | From Profile | To Profile | Operation |
|---|---|---|---|---|
| 390614fd | CreateBreakdownTask EQ+_to_CAFM_Create | af096014 | 362c3ec8 | CreateBreakdownTask |

### Map: CreateBreakdownTask (390614fd)

**From Profile:** af096014 (EQ+_CAFM_Create_Request)  
**To Profile:** 362c3ec8 (CreateBreakdownTask Request)  
**Type:** SOAP Request Map

**Element Names (CRITICAL):**
- Operation Element: CreateBreakdownTask
- DTO Element: breakdownTaskDto
- **RULE:** Use "breakdownTaskDto" in SOAP envelope, NOT generic "dto"

**Namespace Prefixes (CRITICAL):**
- Namespace Declarations: fsi1: Fsi.Concept.Contracts.Entities.ServiceModel
- Field Prefix: CategoryId ‚Üí fsi1:
- **RULE:** All fields in this operation use fsi1: prefix

**Field Mappings:**

| Source Field | Source Type | Target Field (SOAP) | Profile Field Name | Discrepancy? |
|---|---|---|---|---|
| reporterName | profile | ReporterName | ReporterName | ‚úÖ Match |
| reporterEmail | profile | BDET_EMAIL | BDET_EMAIL | ‚úÖ Match |
| DPP_CategoryId | function (process property) | CategoryId | BDET_FKEY_CAT_SEQ | ‚ùå DIFFERENT |
| DDP_DisciplineId | function (process property) | DisciplineId | BDET_FKEY_LAB_SEQ | ‚ùå DIFFERENT |
| DPP_PriorityId | function (process property) | PriorityId | BDET_FKEY_PRI_SEQ | ‚ùå DIFFERENT |
| DPP_BuildingID | function (process property) | BuildingId | BDET_FKEY_BLD_SEQ | ‚ùå DIFFERENT |
| DPP_LocationID | function (process property) | LocationId | BDET_FKEY_LOC_SEQ | ‚ùå DIFFERENT |
| scheduledDate + scheduledTimeStart | function (scripting) | ScheduledDateUtc | BDET_SCHEDULED_DATE | ‚ùå DIFFERENT |
| raisedDateUtc | function (scripting) | RaisedDateUtc | BDET_RAISED_DATE | ‚ùå DIFFERENT |

**Scripting Functions:**

| Function | Input | Output | Logic |
|---|---|---|---|
| Function 11 | scheduledDate, scheduledTimeStart | ScheduledDateUtc | Combine date+time, format to ISO with .0208713Z suffix |
| Function 13 | raisedDateUtc | RaisedDateUtc | Format to ISO with .0208713Z suffix |

**Profile vs Map Discrepancies:**

| Profile Field Name | Map Field Name (ACTUAL) | Authority | Use in SOAP |
|---|---|---|---|
| BDET_FKEY_CAT_SEQ | CategoryId | ‚úÖ MAP | CategoryId |
| BDET_FKEY_LAB_SEQ | DisciplineId | ‚úÖ MAP | DisciplineId |
| BDET_FKEY_PRI_SEQ | PriorityId | ‚úÖ MAP | PriorityId |
| BDET_FKEY_BLD_SEQ | BuildingId | ‚úÖ MAP | BuildingId |
| BDET_FKEY_LOC_SEQ | LocationId | ‚úÖ MAP | LocationId |
| BDET_CONTACT_NAME | ReporterName | ‚úÖ MAP | ReporterName |
| BDET_SCHEDULED_DATE | ScheduledDateUtc | ‚úÖ MAP | ScheduledDateUtc |

**CRITICAL RULE:** Map field names are AUTHORITATIVE. Use map field names in SOAP envelopes, NOT profile field names.
```

### STEP 2: Extract Property WRITES (MANDATORY)

**üõë EXPLICIT ENFORCEMENT:**

**YOU CANNOT PROCEED TO STEP 4** until this step is complete.

**REQUIRED OUTPUT**: You MUST document property writes in Phase 1 document section "Process Properties Analysis" or create dedicated section.

```
  property_writes = {}  # { "process.Property_X": ["shape_A", "shape_B"] }
  
  FOR EACH shape in shapes_by_id.values():
    IF shape.shapetype == "documentproperties":
      FOR EACH assignment in shape.documentproperties.propertyassignments[]:
      property_name = assignment.propertyId  # e.g., "process.Property_SessionId"
          property_writes[property_name].append(shape.shapeId)
        
OUTPUT: Complete list of which shapes WRITE which properties
```

**REQUIRED DOCUMENTATION**: Document in Phase 1:
- List of all properties WRITTEN
- For each property: List which shapes write it
- This data is required for Step 4 (Data Dependency Graph)

**IF PROPERTY WRITES NOT DOCUMENTED ‚Üí Step 2 NOT complete ‚Üí Step 4 will fail**

### STEP 3: Extract Property READS (MANDATORY)

**üõë EXPLICIT ENFORCEMENT:**

**YOU CANNOT PROCEED TO STEP 4** until this step is complete.

**REQUIRED OUTPUT**: You MUST document property reads in Phase 1 document section "Process Properties Analysis" or create dedicated section.

```
property_reads = {}  # { "process.Property_X": ["shape_C", "shape_D"] }

FOR EACH shape in shapes_by_id.values():
  IF shape.shapetype == "connectoraction":
    operation = operations_by_id[shape.connectoraction.operationId]
    # Search operation.request.body for property patterns:
    # - ${process.Property_X}
    # - %process.Property_X%
    # - {process.Property_X}
    # - {1} where parameter references process property
    properties_used = extract_property_references(operation.request.body)
    # Also check operation.request.headers, operation.request.pathParameters
    FOR EACH prop in properties_used:
      property_reads[prop].append(shape.shapeId)
  
  IF shape.shapetype == "message":
    # Search message content for ${process.Property_X} patterns
    properties_used = extract_property_references(shape.message.msgTxt)
    # Check msgParameters array for process property references
    FOR EACH param in shape.message.msgParameters[]:
      IF param.valueType == "process":
        property_reads[param.processparameter.processproperty].append(shape.shapeId)
    FOR EACH prop in properties_used:
      property_reads[prop].append(shape.shapeId)
  
  IF shape.shapetype == "decision":
    # Check decisionvalue for process property references
    FOR EACH decisionvalue in shape.decision.decisionvalue[]:
      IF decisionvalue.valueType == "process":
        property_reads[decisionvalue.processparameter.processproperty].append(shape.shapeId)
      IF decisionvalue.valueType == "track":
        # Track properties are meta properties (e.g., meta.base.applicationstatuscode)
        # These are NOT process properties, but document properties
  
  IF shape.shapetype == "documentproperties":
    # Document properties can READ from other properties
    FOR EACH assignment in shape.documentproperties.propertyassignments[]:
      FOR EACH sourcevalue in assignment.sourcevalues[]:
        IF sourcevalue.valueType == "process":
          property_reads[sourcevalue.processparameter.processproperty].append(shape.shapeId)
  
  IF shape.shapetype == "processcall":
    # Subprocess calls can pass process properties as parameters
    FOR EACH param in shape.processcall.parameters[]:
      IF param.valueType == "process":
        property_reads[param.processparameter.processproperty].append(shape.shapeId)

FUNCTION extract_property_references(text):
  # Search for patterns:
  # 1. ${process.Property_Name}
  # 2. %process.Property_Name%
  # 3. {process.Property_Name}
  # 4. {N} where N is parameter index (check msgParameters/parametervalue array)
  # Returns: ["process.Property_X", "process.Property_Y"]
  properties = []
  # Regex patterns to match
  patterns = [
    r'\$\{process\.([^}]+)\}',
    r'%process\.([^%]+)%',
    r'\{process\.([^}]+)\}'
  ]
  FOR EACH pattern in patterns:
    matches = regex.findall(pattern, text)
    FOR EACH match in matches:
      properties.append(f"process.{match}")
  RETURN properties

OUTPUT: Complete list of which shapes READ which properties
```

**REQUIRED DOCUMENTATION**: Document in Phase 1:
- List of all properties READ
- For each property: List which shapes read it
- This data is required for Step 4 (Data Dependency Graph)

**IF PROPERTY READS NOT DOCUMENTED ‚Üí Step 3 NOT complete ‚Üí Step 4 will fail**

### STEP 4: Build Data Dependency Graph (MANDATORY)

**üõë EXPLICIT ENFORCEMENT - CRITICAL STEP:**

**YOU CANNOT PROCEED TO STEP 8** until this step is complete and documented.

**YOU CANNOT CREATE SEQUENCE DIAGRAM (Step 10)** until this step is documented in Phase 1 document.

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Data Dependency Graph (Step 4)
```

This section MUST be created BEFORE proceeding to Step 8 or Step 10.

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Data Dependency Graph (Step 4)" ‚Üí Step 4 NOT complete ‚Üí **CANNOT PROCEED**

```
  dependencies = {}  # { "shape_A": ["shape_B", "shape_C"] } means A must run before B,C
  
  FOR EACH property_name, reading_shapes in property_reads.items():
    writing_shapes = property_writes.get(property_name, [])
    
    FOR EACH writer in writing_shapes:
      FOR EACH reader in reading_shapes:
        IF writer not in dependencies:
          dependencies[writer] = []
        dependencies[writer].append(reader)
  
OUTPUT: Dependency graph showing which shapes must execute before which other shapes
```

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "Data Dependency Graph (Step 4)":

1. **Dependency Graph**:
   - For each property: List which shapes WRITE it
   - For each property: List which shapes READ it
   - For each dependency: Show "Shape X must execute before Shape Y because Y reads Property_Z which X writes"

2. **Dependency Chains**:
   - Show complete dependency chains (A ‚Üí B ‚Üí C)
   - Identify independent operations (no dependencies)

3. **Property Summary**:
   - List all properties that create dependencies
   - Show which operations depend on which other operations

**IF THIS SECTION IS MISSING OR INCOMPLETE ‚Üí Step 4 NOT complete ‚Üí CANNOT PROCEED**

### STEP 5: Build Control Flow Graph (MANDATORY)

**üõë EXPLICIT ENFORCEMENT:**

**YOU CANNOT PROCEED TO STEP 6** until this step is complete and validated.

**REQUIRED OUTPUT**: You MUST document control flow in Phase 1 document section "Control Flow Graph (Step 5)".

```
control_flow = {}  # { "shape_A": [{"to": "shape_B", "identifier": "true"}] }
  
  FOR EACH shape in shapes_by_id.values():
    IF shape has dragpoints:
      FOR EACH dragpoint in shape.dragpoints[]:
        to_shape_id = dragpoint.toShape
        IF shape.shapeId not in control_flow:
          control_flow[shape.shapeId] = []
        control_flow[shape.shapeId].append({
          "to": to_shape_id,
        "identifier": dragpoint.identifier,  # "true", "false", "default", "error"
          "text": dragpoint.text
        })

OUTPUT: Control flow graph showing dragpoint connections
```

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "Control Flow Graph (Step 5)":

1. **Control Flow Map**:
   - For each shape: List all dragpoint connections (toShape references)
   - Show decision TRUE/FALSE paths
   - Show branch paths
   - Show subprocess return paths

2. **Connection Summary**:
   - Total number of shapes
   - Total number of connections
   - Shapes with multiple outgoing connections (branches, decisions)

**IF THIS SECTION IS MISSING ‚Üí Step 5 NOT complete ‚Üí CANNOT PROCEED**

**üîç SELF-CHECK (MANDATORY before proceeding):**
- [ ] Did I read dragpoints from JSON file? (Answer: YES/NO)
- [ ] If NO ‚Üí STOP, read actual dragpoints from process JSON file
- [ ] If YES ‚Üí List line numbers where dragpoints were read: ___________

**VALIDATION:**
- [ ] Every shape with dragpoints has been processed
- [ ] All toShape references extracted
- [ ] All identifiers (true/false/default/error) extracted
- [ ] Control flow graph is complete

### STEP 6: Build Reverse Flow Mapping (MANDATORY - For Convergence Detection)

**üõë EXPLICIT ENFORCEMENT:**

**YOU CANNOT PROCEED TO STEP 7** until this step is complete.

**REQUIRED OUTPUT**: You MUST document reverse flow mapping in Phase 1 document section "Control Flow Graph (Step 5)" or create dedicated section.

```
  incoming_connections = {}  # { "shape_X": ["shape_A", "shape_B"] } means A and B both point to X
  
  FOR EACH source_shape_id, destinations in control_flow.items():
    FOR EACH destination in destinations:
      target_shape_id = destination["to"]
      IF target_shape_id not in incoming_connections:
        incoming_connections[target_shape_id] = []
    incoming_connections[target_shape_id].append(source_shape_id)

OUTPUT: Reverse mapping to identify convergence points (shapes reached by multiple paths)
```

**REQUIRED DOCUMENTATION**: Document in Phase 1:
- List of convergence points (shapes reached by multiple paths)
- For each convergence point: List which paths converge there
- This data is required for Step 8 (Branch Analysis) to identify where branch paths converge

**IF REVERSE FLOW MAPPING NOT DOCUMENTED ‚Üí Step 6 NOT complete ‚Üí Step 8 will fail**

### STEP 7: Decision Shape Inventory (MANDATORY - BLOCKING)

**üõë EXPLICIT ENFORCEMENT - CRITICAL BLOCKING STEP:**

**YOU CANNOT PROCEED TO STEP 8** until this step is complete and documented.

**YOU CANNOT CREATE SEQUENCE DIAGRAM (Step 10)** until this step is documented in Phase 1 document.

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Decision Shape Analysis (Step 7)
```

This section MUST be created BEFORE proceeding to Step 8 or Step 10.

**üö® CRITICAL NEW REQUIREMENT: Decision Data Source Analysis**

**YOU MUST identify whether each decision checks INPUT data or RESPONSE data from previous operations.**

**This is CRITICAL because:**
- Decisions that check INPUT data are PRE-FILTERS (may route before operations)
- Decisions that check RESPONSE data are POST-OPERATION (execute after operations)
- **Business logic may require operations to execute FIRST, even if decision appears before them in dragpoint flow**

**üîç SELF-CHECK (MANDATORY - MUST BE DOCUMENTED IN PHASE 1):**

**REQUIRED**: You MUST show these self-check answers in the Phase 1 document section "Decision Shape Analysis (Step 7)".

- [ ] Did I identify data source for EVERY decision? (INPUT vs RESPONSE vs PROCESS property) (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show answer in Phase 1 document: "‚úÖ Decision data sources identified: YES/NO"
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Analyze each decision's data source ‚Üí Show in Phase 1 ‚Üí Then proceed
  
- [ ] Did I classify each decision type? (PRE-FILTER vs POST-OPERATION) (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Decision types classified: YES" + classification for each decision
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Classify each decision ‚Üí Show in Phase 1 ‚Üí Then proceed

- [ ] Did I verify actual execution order for PRE-FILTER decisions? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Execution order verified: YES" + actual order for each decision
  - **CRITICAL**: If decision is PRE-FILTER but business logic requires operation first ‚Üí Document actual order
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Verify execution order ‚Üí Show in Phase 1 ‚Üí Then proceed

- [ ] Did I trace BOTH TRUE and FALSE paths for EVERY decision? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show answer in Phase 1 document: "‚úÖ All decision paths traced: YES/NO"
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Trace all paths to termination ‚Üí Show in Phase 1 ‚Üí Then proceed
  
- [ ] Did I identify the pattern for each decision? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Decision patterns identified: YES" + list of patterns

- [ ] Did I trace paths to termination? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Paths traced to termination: YES" + termination points

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Decision Shape Analysis (Step 7)" ‚Üí Step 7 NOT complete ‚Üí **CANNOT PROCEED**
- If self-check answers are NOT shown in Phase 1 document ‚Üí Step 7 NOT complete ‚Üí **CANNOT PROCEED**
- If decision data source analysis is NOT documented ‚Üí Step 7 NOT complete ‚Üí **CANNOT PROCEED**
- If any self-check answer is NO ‚Üí **STOP ALL WORK** ‚Üí Complete that step ‚Üí Show in Phase 1 ‚Üí Then proceed

```
decision_inventory = []

FOR EACH shape in shapes_by_id.values():
  IF shape.shapetype == "decision":
    # Extract comparison
    comparison_type = shape.decision.comparison  # "equals", "regex", "notequals", etc.
    value1 = shape.decision.decisionvalue[0]
    value2 = shape.decision.decisionvalue[1]
    
    # üö® CRITICAL NEW STEP: Identify Decision Data Source
    data_source = identify_decision_data_source(shape, value1, value2)
    # Returns: "INPUT", "RESPONSE", "PROCESS_PROPERTY", "TRACK_PROPERTY"
    
    # Classify decision type based on data source
    decision_type = classify_decision_type(data_source, shape)
    # Returns: "PRE_FILTER" or "POST_OPERATION"
    
    # Verify actual execution order
    actual_execution_order = verify_execution_order(shape, decision_type, data_source)
    # Returns: Actual order (e.g., "Operation ‚Üí Decision ‚Üí Next Action")
    
    # Find TRUE and FALSE paths
    true_dragpoint = find_dragpoint_by_identifier(shape, "true")
    false_dragpoint = find_dragpoint_by_identifier(shape, "false")
    
    # Trace BOTH paths to termination
    true_path_termination = trace_to_termination(true_dragpoint.toShape)
    false_path_termination = trace_to_termination(false_dragpoint.toShape)
    
    # Identify pattern type
    pattern = identify_decision_pattern(comparison_type, value1, value2, 
                                       true_path_termination, false_path_termination)
    
    # Check for convergence
    convergence_point = check_convergence(true_path_termination, false_path_termination)
    
    decision_inventory.append({
      "shapeId": shape.shapeId,
      "comparison": comparison_type,
      "value1": value1,
      "value2": value2,
      "dataSource": data_source,  # NEW
      "decisionType": decision_type,  # NEW: PRE_FILTER or POST_OPERATION
      "actualExecutionOrder": actual_execution_order,  # NEW
      "truePath": {"toShape": true_dragpoint.toShape, "termination": true_path_termination},
      "falsePath": {"toShape": false_dragpoint.toShape, "termination": false_path_termination},
      "pattern": pattern,
      "convergencePoint": convergence_point,
      "earlyExit": true_path_termination.type == "return" OR false_path_termination.type == "return"
    })

FUNCTION identify_decision_data_source(decision_shape, value1, value2):
  """
  Identify whether decision checks INPUT, RESPONSE, PROCESS property, or TRACK property
  """
  data_source = None
  
  FOR EACH decisionvalue in [value1, value2]:
    IF decisionvalue.valueType == "profile":
      # Check if profile is INPUT profile or RESPONSE profile
      profile_id = decisionvalue.profileelement.profileId
      profile_json = profiles_by_id[profile_id]
      
      # Check if this profile is used as INPUT (entry operation request) or RESPONSE (operation response)
      IF profile_id == entry_operation.requestProfile:
        data_source = "INPUT"
      ELSE:
        # Check if this profile is used as response for any operation
        FOR EACH operation in operations_by_id.values():
          IF operation.responseProfile == profile_id:
            data_source = "RESPONSE"
            BREAK
        IF data_source is None:
          data_source = "UNKNOWN_PROFILE"  # Need to investigate
    
    ELIF decisionvalue.valueType == "track":
      # Track properties come from operation responses (e.g., meta.base.applicationstatuscode)
      data_source = "TRACK_PROPERTY"  # Implies POST-OPERATION
    
    ELIF decisionvalue.valueType == "process":
      # Process properties are written by previous operations
      property_name = decisionvalue.processparameter.processproperty
      # Check if this property is written by any operation
      IF property_name in property_writes:
        data_source = "PROCESS_PROPERTY"  # Implies POST-OPERATION
      ELSE:
        data_source = "PROCESS_PROPERTY_UNKNOWN"  # Need to investigate
    
    ELIF decisionvalue.valueType == "static":
      # Static values don't indicate data source - check the other value
      CONTINUE
  
  RETURN data_source

FUNCTION classify_decision_type(data_source, decision_shape):
  """
  Classify decision as PRE-FILTER (checks input, routes before operations) 
  or POST-OPERATION (checks response/properties, executes after operations)
  """
  IF data_source == "INPUT":
    # INPUT decisions are typically PRE-FILTERS
    # BUT: Verify if business logic requires operation to execute first
    return "PRE_FILTER"
  
  ELIF data_source == "RESPONSE" OR data_source == "TRACK_PROPERTY" OR data_source == "PROCESS_PROPERTY":
    # These decisions check data from operations, so they are POST-OPERATION
    return "POST_OPERATION"
  
  ELSE:
    return "UNKNOWN"  # Need to investigate

FUNCTION verify_execution_order(decision_shape, decision_type, data_source):
  """
  Verify actual execution order - even if decision is PRE-FILTER, 
  business logic may require operations to execute first
  """
  IF decision_type == "PRE_FILTER":
    # Check if any operations in TRUE/FALSE paths need to execute first
    # Example: Decision checks INPUT field, but OperationA must execute first
    # Then check response to determine condition
    
    # Trace paths to find operations
    true_path_operations = find_operations_in_path(decision_shape.truePath.toShape)
    false_path_operations = find_operations_in_path(decision_shape.falsePath.toShape)
    
    # Check if any operation produces data needed by other operations
    FOR EACH operation in true_path_operations + false_path_operations:
      operation_response = get_operation_response(operation)
      IF operation_response is not None:
        # Check if response data is used in subsequent operations or decisions
        IF response_data_used_later(operation_response):
          # Business logic requires operation to execute first
          RETURN f"Operation {operation} ‚Üí Check Response ‚Üí Decision ‚Üí Next Action"
    
    # No operations need to execute first - decision is true PRE-FILTER
    RETURN "Decision ‚Üí Route to Operations"
  
  ELIF decision_type == "POST_OPERATION":
    # Find which operation produces the data this decision checks
    source_operation = find_operation_that_produces_data(data_source, decision_shape)
    RETURN f"Operation {source_operation} ‚Üí Response ‚Üí Decision ‚Üí Next Action"
  
  ELSE:
    RETURN "UNKNOWN"  # Need to investigate

FUNCTION trace_to_termination(start_shape_id):
  current = start_shape_id
  path = [current]
  visited = set()
  
  WHILE current not in visited:
    visited.add(current)
    shape = shapes_by_id[current]
    
    IF shape.shapetype == "returndocuments":
      RETURN {"type": "return", "path": path}
    IF shape.shapetype == "stop" AND shape.stop.continue != "true":
      RETURN {"type": "stop", "path": path}
    IF shape.shapetype == "exception":
      RETURN {"type": "exception", "path": path}
    
    dragpoints = get_dragpoints(shape)
    IF len(dragpoints) == 0:
      RETURN {"type": "end_of_path", "path": path}
    
    current = dragpoints[0].toShape
    path.append(current)
  
  RETURN {"type": "rejoins", "path": path}

FUNCTION identify_decision_pattern(comparison, val1, val2, true_term, false_term):
  # Pattern 1: Existence Check (check-before-create)
  IF comparison == "equals" AND val2 is empty string:
    IF true_term.type == "continue" AND false_term.type == "return":
      RETURN "Existence Check (Create if Not Found)"
    IF false_term.type == "continue" AND true_term.type == "return":
      RETURN "Existence Check (Return if Found)"
  
  # Pattern 2: Validation Check
  IF comparison in ["equals", "notequals", "regex"]:
    IF true_term.type == "continue" AND false_term.type == "exception":
      RETURN "Validation Check (Continue if Valid)"
  
  # Pattern 3: Conditional Logic
  IF comparison in ["equals", "notequals", "contains"]:
    IF both paths eventually rejoin:
      RETURN "Conditional Logic (Optional Processing)"
    IF one path terminates early:
      RETURN "Conditional Logic (Early Exit)"
  
  # Pattern 4: Error Check
  IF comparison checks error status:
    RETURN "Error Check (Success vs Failure)"
  
  RETURN "General Branching Logic"

OUTPUT: Complete decision inventory with patterns and early exits identified, data sources identified, and execution order verified
```

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "Decision Shape Analysis (Step 7)":

1. **Decision Data Source Analysis (NEW - MANDATORY):**
   - For each decision: Data source (INPUT, RESPONSE, PROCESS_PROPERTY, TRACK_PROPERTY)
   - **PROOF**: Show JSON reference where data source is identified
   - Example: "shapeX checks INPUT profile (fieldName field from request)"

2. **Decision Type Classification (NEW - MANDATORY):**
   - For each decision: Type (PRE_FILTER or POST_OPERATION)
   - **PROOF**: Show reasoning based on data source
   - Example: "shapeX is PRE_FILTER (checks INPUT data)"

3. **Actual Execution Order Verification (NEW - MANDATORY):**
   - For each decision: Actual execution order
   - **CRITICAL**: If PRE_FILTER but business logic requires operation first ‚Üí Document actual order
   - Example: "shapeX is PRE_FILTER, but OperationA executes FIRST, then check response, then decision routes"
   - **PROOF**: Show which operations execute before/after decision

4. **Decision Inventory:**
   - For each decision: Shape ID, comparison type, values
   - TRUE path destination and termination
   - FALSE path destination and termination
   - Pattern type (check-before-create, validation, conditional logic, etc.)
   - Convergence points (if paths rejoin)
   - Early exits (if any path leads to return)

5. **Decision Patterns:**
   - List of patterns identified (check-before-create, validation, conditional routing, etc.)
   - For each pattern: Which decisions use it

**IF DECISION DATA SOURCE ANALYSIS IS MISSING ‚Üí Step 7 NOT complete ‚Üí CANNOT PROCEED**
**IF DECISION TYPE CLASSIFICATION IS MISSING ‚Üí Step 7 NOT complete ‚Üí CANNOT PROCEED**
**IF ACTUAL EXECUTION ORDER IS NOT VERIFIED ‚Üí Step 7 NOT complete ‚Üí CANNOT PROCEED**

### STEP 7a: Subprocess Analysis (MANDATORY)

**üõë FOR EACH processcall shape, analyze subprocess internal flow**

```
FOR EACH shape in shapes_by_id.values():
  IF shape.shapetype == "processcall":
    subprocess_id = shape.processcall.processId
    subprocess_json = load_subprocess(subprocess_id)
    
    # Step 1: Analyze subprocess internal flow
    subprocess_flow = trace_subprocess_flow(subprocess_json)
    
    # Step 2: Identify return paths
    return_paths = []
    FOR EACH shape in subprocess_json.shapes[]:
      IF shape.shapetype == "returndocuments":
        return_paths.append({
          "label": shape.returndocuments.label,
          "shapeId": shape.shapeId,
          "path": trace_path_to_return(shape.shapeId)
        })
      IF shape.shapetype == "stop" AND shape.stop.continue == "true":
        # This is implicit success return
        return_paths.append({
          "label": "SUCCESS",
          "shapeId": shape.shapeId,
          "path": trace_path_to_stop(shape.shapeId)
        })
    
    # Step 3: Map return paths to main process
    main_process_return_mapping = {}
    FOR EACH returnpath in shape.processcall.returnpaths[]:
      main_process_return_mapping[returnpath.returnLabel] = returnpath.childShapeName
    
    # Step 4: Identify properties written by subprocess
    subprocess_writes = extract_property_writes(subprocess_json)
    
    # Step 5: Identify properties read by subprocess (from main process)
    subprocess_reads = extract_property_reads(subprocess_json)
    
    subprocess_analysis = {
      "subprocessId": subprocess_id,
      "internalFlow": subprocess_flow,
      "returnPaths": return_paths,
      "mainProcessMapping": main_process_return_mapping,
      "writes": subprocess_writes,
      "reads": subprocess_reads
    }

FUNCTION trace_subprocess_flow(subprocess_json):
  # Trace from START to all termination points
  start_shape = find_shape_by_type("start", subprocess_json)
  flow = []
  traverse_subprocess(start_shape.shapeId, flow, subprocess_json)
  RETURN flow

OUTPUT: Complete subprocess analysis including internal flow and return paths
```

**CRITICAL RULES:**
1. **Subprocesses are NOT black boxes** - You MUST trace internal flow
2. **Return paths matter** - Each return label maps to different main process path
3. **Properties written in subprocess** - Available to main process after subprocess returns
4. **Error paths** - Check for explicit return paths with error labels

### STEP 8: Branch Shape Analysis (MANDATORY)

**üõë EXPLICIT ENFORCEMENT - CRITICAL BLOCKING STEP:**

**YOU CANNOT PROCEED TO STEP 9** until this step is complete and documented.

**YOU CANNOT CREATE SEQUENCE DIAGRAM (Step 10)** until this step is documented in Phase 1 document.

**üö® DO NOT ASSUME - YOU MUST ANALYZE:**

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Branch Shape Analysis (Step 8)
```

This section MUST be created BEFORE proceeding to Step 9 or Step 10.

**üîç SELF-CHECK (MANDATORY - MUST BE DOCUMENTED IN PHASE 1):**

**REQUIRED**: You MUST show these self-check answers in the Phase 1 document section "Branch Shape Analysis (Step 8)".

- [ ] Did I classify each branch as parallel or sequential? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show answer in Phase 1 document: "‚úÖ Classification completed: YES/NO"
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Complete classification using dependency analysis ‚Üí Show in Phase 1 ‚Üí Then proceed
  
- [ ] Did I assume branches are parallel? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show answer in Phase 1 document: "‚úÖ Assumption check: NO (analyzed dependencies)"
  - If YES ‚Üí **STOP ALL WORK** ‚Üí REDO, check data dependencies first ‚Üí Show proof in Phase 1 ‚Üí Then proceed

- [ ] Did I extract properties read/written by each path? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Properties extracted: YES" + list of properties

- [ ] Did I build dependency graph between paths? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show dependency graph in Phase 1 document

- [ ] Did I apply topological sort if sequential? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show topological sort order in Phase 1 document

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Branch Shape Analysis (Step 8)" ‚Üí Step 8 NOT complete ‚Üí **CANNOT PROCEED**
- If self-check answers are NOT shown in Phase 1 document ‚Üí Step 8 NOT complete ‚Üí **CANNOT PROCEED**
- If any self-check answer is NO ‚Üí **STOP ALL WORK** ‚Üí Complete that step ‚Üí Show in Phase 1 ‚Üí Then proceed

**For EACH branch shape, complete this 8-step analysis:**

```
FUNCTION any_path_contains_api_calls(branch_paths):
  """
  Check if ANY path in branch contains API calls (connectoraction with HTTP/SOAP/REST operations)
  """
  FOR EACH path in branch_paths:
    FOR EACH shape in path:
      IF shape.shapetype == "connectoraction":
        operation = operations_by_id[shape.connectoraction.operationId]
        IF operation.subType in ["http", "soap", "rest", "wss"]:
          RETURN True
  RETURN False

FUNCTION branch_contains_api_calls(branch_shape):
  """
  Check if branch shape contains any API calls in its paths
  """
  branch_paths = extract_branch_paths(branch_shape)
  RETURN any_path_contains_api_calls(branch_paths)

FOR EACH branch_shape:
  Step 1: Extract properties read/written by each path
    path_properties = {}
    FOR EACH path in branch_paths:
      path_properties[path] = {
        "reads": extract_properties_read(path),
        "writes": extract_properties_written(path)
      }
  
  Step 2: Build dependency graph between paths
    path_dependencies = {}
    FOR EACH path_A in branch_paths:
      FOR EACH path_B in branch_paths:
        IF path_A != path_B:
          IF path_B reads any property that path_A writes:
            path_dependencies[path_A].append(path_B)
  
  Step 3: Classify as parallel or sequential
    # üö® CRITICAL RULE: ALL API CALLS ARE SEQUENTIAL
    # If ANY path contains API calls (connectoraction with HTTP/SOAP/REST), classification is ALWAYS SEQUENTIAL
    IF any_path_contains_api_calls(branch_paths):
      classification = "SEQUENTIAL"  # API calls are ALWAYS sequential
    ELIF path_dependencies is empty:
      classification = "PARALLEL"  # Only non-API operations can be parallel
    ELSE:
      classification = "SEQUENTIAL"
  
  Step 4: Build dependency_order using topological sort (if sequential)
    IF classification == "SEQUENTIAL":
      dependency_order = topological_sort(path_dependencies)
      # Topological sort algorithm:
      # 1. Find paths with no dependencies (incoming edges = 0)
      # 2. Add to sorted list
      # 3. Remove from graph
      # 4. Repeat until all paths sorted
      # 5. If cycle detected ‚Üí ERROR (invalid dependencies)
  
  Step 5: Trace each path to terminal point
    path_terminals = {}
    FOR EACH path in branch_paths:
      terminal = trace_to_termination(path[0])  # Start from first shape in path
      path_terminals[path] = terminal
  
  Step 6: Identify convergence points
    convergence_points = []
    FOR EACH shape_id, incoming in incoming_connections.items():
      IF len(incoming) > 1 AND shape_id is reached by multiple branch paths:
        convergence_points.append(shape_id)
  
  Step 7: Determine execution continuation
    IF convergence_points exist:
      execution_continues_from = convergence_points[0]  # First convergence point
    ELSE:
      execution_continues_from = None  # Each path continues independently
  
  Step 8: Document complete analysis
    branch_analysis = {
      "shapeId": branch_shape.shapeId,
      "numPaths": len(branch_paths),
      "classification": classification,
      "dependencyOrder": dependency_order if sequential else None,
      "pathTerminals": path_terminals,
      "convergencePoints": convergence_points,
      "executionContinuesFrom": execution_continues_from
    }

OUTPUT: Complete branch analysis for each branch shape

**REQUIRED DOCUMENTATION IN PHASE 1:**

For EACH branch shape, you MUST document in Phase 1 section "Branch Shape Analysis (Step 8)":

1. **Branch Shape Identification**:
   - Shape ID
   - Number of paths
   - Location in process flow

2. **Properties Analysis** (Step 1):
   - For each path: Properties READ (extracted from JSON)
   - For each path: Properties WRITTEN (extracted from JSON)
   - **PROOF**: Show JSON references where properties are read/written

3. **Dependency Graph** (Step 2):
   - Show which paths depend on which other paths
   - **PROOF**: Show reasoning: "Path 2 reads process.Property_SessionId which Path 1 writes, therefore Path 2 depends on Path 1"

4. **Classification** (Step 3):
   - Classification: PARALLEL or SEQUENTIAL
   - **üö® CRITICAL**: If ANY path contains API calls ‚Üí Classification is ALWAYS SEQUENTIAL
   - **PROOF**: Show reasoning based on dependency graph AND API call detection
   - If PARALLEL: "No dependencies between paths AND no API calls in any path"
   - If SEQUENTIAL: "Path X depends on Path Y because..." OR "Path contains API calls (sequential execution required)"

5. **Topological Sort Order** (Step 4, if sequential):
   - Show execution order: Path 1 ‚Üí Path 2 ‚Üí Path 3
   - **üö® CRITICAL**: If paths contain API calls, they execute sequentially in order (no parallel execution)
   - If paths have no API calls but have dependencies: Show topological sort order

6. **Path Termination** (Step 5):
   - For each path: Where it terminates (shape ID)

7. **Convergence Points** (Step 6):
   - Where branch paths converge (if any)

8. **Self-Check Results**:
   - ‚úÖ All self-checks answered YES
   - ‚úÖ All answers shown in Phase 1 document

**IF ANY OF THE ABOVE IS MISSING ‚Üí Step 8 NOT complete ‚Üí CANNOT PROCEED**
```

### STEP 9: Derive Execution Order (MANDATORY)

**üõë EXPLICIT ENFORCEMENT - CRITICAL BLOCKING STEP:**

**YOU CANNOT PROCEED TO STEP 10** until this step is complete and documented.

**YOU CANNOT CREATE SEQUENCE DIAGRAM (Step 10)** until this step is documented in Phase 1 document.

**PREREQUISITE VALIDATION**: 
- ‚úÖ Step 1c (Operation Response Analysis) MUST be complete and documented in Phase 1 (required for business logic verification)
- ‚úÖ Step 4 (Data Dependency Graph) MUST be complete and documented in Phase 1 (required for dependency verification)
- ‚úÖ Step 7 (Decision Analysis) MUST be complete and documented in Phase 1 (required for decision execution order)
- ‚úÖ Step 8 (Branch Analysis) MUST be complete and documented in Phase 1 (required for branch execution order)
- ‚úÖ If Step 1c, Step 4, Step 7, or Step 8 section missing from Phase 1 ‚Üí **STOP** ‚Üí Complete missing steps first

**üö® CRITICAL RULE: Business Logic ALWAYS Overrides Dragpoints**
**üö® CRITICAL RULE: Data Dependencies ALWAYS Override Dragpoints**

**REQUIRED OUTPUT**: You MUST create a section in Phase 1 document titled:
```
## Execution Order (Step 9)
```
 
üî¥ CRITICAL: Step 9 = WHY (analysis), Step 10 = WHAT (diagram)
Do NOT duplicate content - Step 10 should reference Step 9 for reasoning
This section MUST be created BEFORE proceeding to Step 10.
Document the REASONING for execution order
Show dependency chains
Explain WHY operations must execute in specific order

**üö® NEW REQUIREMENT: Business Logic Verification (Step 0 - MUST DO FIRST)**

**YOU CANNOT derive execution order until business logic is verified.**

**REQUIRED OUTPUT**: You MUST document business logic in Phase 1 section "Execution Order (Step 9)" BEFORE deriving execution order.

**üîç SELF-CHECK (MANDATORY - MUST BE DOCUMENTED IN PHASE 1):**

**REQUIRED**: You MUST show these self-check answers in the Phase 1 document section "Execution Order (Step 9)".

- [ ] Did I verify business logic FIRST before following dragpoints? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show answer in Phase 1 document: "‚úÖ Business logic verified FIRST: YES/NO"
  - **CRITICAL**: Business logic section MUST be documented before execution order
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Verify business logic ‚Üí Document in Phase 1 ‚Üí Then proceed

- [ ] Did I identify what each operation does and what it produces? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Operation analysis complete: YES" + list of operations with their purposes and outputs

- [ ] Did I identify which operations MUST execute first based on business logic? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Business logic execution order identified: YES" + list of operations that must execute first

- [ ] Did I check data dependencies FIRST before following dragpoints? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show answer in Phase 1 document: "‚úÖ Data dependencies checked FIRST: YES/NO"
  - If NO ‚Üí **STOP ALL WORK** ‚Üí Rebuild execution order checking dependencies first ‚Üí Show in Phase 1 ‚Üí Then proceed
  
- [ ] Did I use operation response analysis from Step 1c? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Operation response analysis used: YES" + reference to Step 1c section

- [ ] Did I use decision analysis from Step 7? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Decision analysis used: YES" + reference to Step 7 section

- [ ] Did I use dependency graph from Step 4? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Dependency graph used: YES" + reference to Step 4 section

- [ ] Did I use branch analysis from Step 8? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Branch analysis used: YES" + reference to Step 8 section

- [ ] Did I verify all property reads happen after property writes? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show verification in Phase 1 document: "‚úÖ Property dependency verification: YES" + list of verified dependencies

- [ ] Did I follow topological sort order for sequential branches? (Answer: YES/NO)
  - **REQUIRED OUTPUT**: Show in Phase 1 document: "‚úÖ Topological sort applied: YES" + execution order

**VALIDATION CHECKPOINT**: 
- If Phase 1 document does NOT contain section "Execution Order (Step 9)" ‚Üí Step 9 NOT complete ‚Üí **CANNOT PROCEED**
- If business logic verification is NOT documented ‚Üí Step 9 NOT complete ‚Üí **CANNOT PROCEED**
- If self-check answers are NOT shown in Phase 1 document ‚Üí Step 9 NOT complete ‚Üí **CANNOT PROCEED**
- If any self-check answer is NO ‚Üí **STOP ALL WORK** ‚Üí Complete that step ‚Üí Show in Phase 1 ‚Üí Then proceed

```
# STEP 0: Business Logic Verification (MUST DO FIRST)

business_logic_flow = []

FOR EACH operation in operations_by_id.values():
  # Question 1: What does this operation do?
  operation_purpose = identify_operation_purpose(operation)
  
  # Question 2: What does it produce? (response data, properties)
  operation_outputs = []
  IF operation has responseProfile:
    # Check Step 1c analysis for response structure
    response_analysis = get_operation_response_analysis(operation.operationId)
    operation_outputs.extend(response_analysis.extractedFields)
  
  # Check what properties this operation writes (via documentproperties shapes)
  FOR EACH shape in shapes_after_operation(operation):
    IF shape.shapetype == "documentproperties":
      FOR EACH assignment in shape.documentproperties.propertyassignments[]:
        operation_outputs.append({
          "type": "process_property",
          "property": assignment.propertyId,
          "writtenBy": shape.shapeId
        })
  
  # Question 3: What operations depend on this operation's output?
  dependent_operations = []
  FOR EACH output in operation_outputs:
    IF output.type == "process_property":
      property_name = output.property
      # Find operations that read this property
      IF property_name in property_reads:
        dependent_operations.extend(property_reads[property_name])
  
  # Question 4: What is the actual business flow?
  business_flow = determine_business_flow(operation, operation_purpose, operation_outputs, dependent_operations)
  
  business_logic_flow.append({
    "operationId": operation.operationId,
    "operationName": operation.name,
    "purpose": operation_purpose,
    "outputs": operation_outputs,
    "dependentOperations": dependent_operations,
    "businessFlow": business_flow
  })

FUNCTION identify_operation_purpose(operation):
  """
  Identify what the operation does based on operation name, type, and configuration
  """
  # Check operation name for keywords
  IF "Login" in operation.name OR "Authenticate" in operation.name:
    RETURN "Authentication - Establishes session"
  ELIF "Create" in operation.name:
    RETURN "Create entity - Creates new record"
  ELIF "Get" in operation.name OR "Read" in operation.name:
    RETURN "Read entity - Retrieves existing record"
  ELIF "Update" in operation.name:
    RETURN "Update entity - Modifies existing record"
  ELIF "Delete" in operation.name:
    RETURN "Delete entity - Removes record"
  ELSE:
    RETURN "Process data - Performs business operation"

FUNCTION determine_business_flow(operation, purpose, outputs, dependents):
  """
  Determine actual business flow based on operation purpose and dependencies
  """
  flow = []
  
  # If operation produces data that others need, it must execute first
  IF len(dependents) > 0:
    flow.append(f"{operation.name} MUST execute FIRST (produces data needed by {len(dependents)} operations)")
  
  # If operation consumes data from others, it must execute after
  operation_reads = get_properties_read_by_operation(operation)
  IF len(operation_reads) > 0:
    writers = []
    FOR EACH prop in operation_reads:
      IF prop in property_writes:
        writers.extend(property_writes[prop])
    IF len(writers) > 0:
      flow.append(f"{operation.name} MUST execute AFTER {writers} (consumes their output)")
  
  # Document business logic pattern
  IF "Create" in purpose AND len(dependents) > 0:
    flow.append(f"Business Pattern: {operation.name} creates entity, then {dependents} use created entity")
  
  RETURN flow

OUTPUT: Complete business logic flow showing what operations do, what they produce, and actual execution order

# STEP 1: Derive Execution Order (following business logic and data dependencies)

  execution_order = []
  visited = set()
  
FUNCTION traverse(current_shape_id):
    IF current_shape_id in visited:
      RETURN
    
    shape = shapes_by_id[current_shape_id]
    
  # MANDATORY: Check data dependencies FIRST
    IF shape requires properties:
      FOR EACH required_property:
        IF property not yet written:
          writer_shape = find_writer(required_property)
        traverse(writer_shape)  # Execute writer first
    
    # Execute current shape
    execution_order.append(current_shape_id)
    visited.add(current_shape_id)
    
    # Handle shape-specific logic
    IF shape.shapetype == "branch":
    branch_analysis = get_branch_analysis(shape.shapeId)
    
    # üö® CRITICAL: ALL API CALLS ARE SEQUENTIAL
    # If branch contains API calls, it is ALWAYS sequential
    IF branch_analysis.classification == "SEQUENTIAL" OR branch_contains_api_calls(shape):
      # Execute paths in dependency order (or sequential order if API calls present)
      FOR EACH path in branch_analysis.dependencyOrder:
        traverse(path[0])  # Start from first shape in path
      
      # Execution continues from convergence point
      IF branch_analysis.executionContinuesFrom:
        traverse(branch_analysis.executionContinuesFrom)
    ELSE:
      # Parallel execution (ONLY for non-API operations)
      execution_order.append("PARALLEL_START")
      FOR EACH path in branch_paths:
        traverse(path[0])
      execution_order.append("PARALLEL_END")
      
      IF branch_analysis.executionContinuesFrom:
        traverse(branch_analysis.executionContinuesFrom)
    
    ELIF shape.shapetype == "decision":
    decision_info = get_decision_info(shape.shapeId)
    execution_order.append(f"DECISION: {decision_info.comparison}")
    
    # Trace TRUE path
      execution_order.append("IF TRUE:")
    traverse(decision_info.truePath.toShape)
    
    # Trace FALSE path
      execution_order.append("IF FALSE:")
    traverse(decision_info.falsePath.toShape)
    
    # Check for convergence
    IF decision_info.convergencePoint:
      traverse(decision_info.convergencePoint)
    
  ELIF shape.shapetype == "processcall":
    subprocess_analysis = get_subprocess_analysis(shape.shapeId)
    execution_order.append(f"SUBPROCESS: {subprocess_analysis.subprocessId}")
    
    # Document subprocess internal flow
    FOR EACH step in subprocess_analysis.internalFlow:
      execution_order.append(f"  SUBPROCESS_STEP: {step}")
    
    # After subprocess returns, check return path
    # If explicit return path exists, follow that
    # Otherwise, continue to next shape
    next_shapes = control_flow.get(current_shape_id, [])
    FOR EACH next in next_shapes:
      traverse(next["to"])
  
  ELIF shape.shapetype == "stop":
    IF shape.stop.continue == "true":
      # Continue to next shape
      next_shapes = control_flow.get(current_shape_id, [])
      FOR EACH next in next_shapes:
        traverse(next["to"])
    ELSE:
      execution_order.append("END")
  
  ELIF shape.shapetype == "catcherrors":
    # Try/Catch: default path and error path
    default_path = find_dragpoint_by_identifier(shape, "default")
    error_path = find_dragpoint_by_identifier(shape, "error")
    
    execution_order.append("TRY:")
    traverse(default_path.toShape)
    
    execution_order.append("CATCH:")
    traverse(error_path.toShape)
  
  ELSE:
    # Regular shape: follow control flow
    next_shapes = control_flow.get(current_shape_id, [])
    FOR EACH next in next_shapes:
      traverse(next["to"])

# Start traversal from START shape
start_shape = find_shape_by_type("start")
traverse(start_shape.shapeId)

OUTPUT: Complete execution order respecting data dependencies

**REQUIRED DOCUMENTATION IN PHASE 1:**

You MUST document in Phase 1 section "Execution Order (Step 9)":

1. **Business Logic Flow (Step 0 - MUST BE FIRST):**
   - For each operation: What does it do? (purpose)
   - For each operation: What does it produce? (response data, properties)
   - For each operation: What operations depend on its output?
   - Actual business flow: What happens first, second, third?
   - Operations that MUST execute first (produce required data)
   - Operations that execute after (consume data from previous operations)
   - **PROOF**: Show reasoning for each operation's position in business flow
   - **EXAMPLE**: "OperationA creates an entity ‚Üí Response contains EntityId ‚Üí If condition met, OperationB links to entity using EntityId ‚Üí Therefore, OperationA MUST execute BEFORE OperationB"

2. **Execution Order List**:
   - Complete ordered list of shapes/operations
   - Show parallel execution groups: [Path1, Path2, Path3] (parallel)
   - Show sequential execution: Path1 ‚Üí Path2 ‚Üí Path3

2. **Dependency Verification**:
   - Reference to Step 4 (Data Dependency Graph)
   - For each operation: Show which properties it reads
   - For each property read: Show which operation writes it (must execute before)
   - **PROOF**: "OperationX reads process.Property_SessionId ‚Üí OperationY writes process.Property_SessionId ‚Üí OperationY must execute before OperationX"

3. **Branch Execution Order**:
   - Reference to Step 8 (Branch Analysis)
   - Show how branch paths are ordered based on dependencies
   - Show topological sort order if sequential

4. **Decision Path Tracing**:
   - For each decision: Show TRUE path execution order
   - For each decision: Show FALSE path execution order
   - Show convergence points

5. **Self-Check Results**:
   - ‚úÖ All self-checks answered YES
   - ‚úÖ All answers shown in Phase 1 document

**IF ANY OF THE ABOVE IS MISSING ‚Üí Step 9 NOT complete ‚Üí CANNOT PROCEED**
```

### STEP 10: Create Sequence Diagram (MANDATORY FORMAT)
- Create VISUAL diagram based on Step 9 analysis
- Use ASCII format
- Include technical details: READS, WRITES, HTTP codes
- Reference Step 9 for reasoning
- This is the DIAGRAM section

**üõë EXPLICIT ENFORCEMENT - PRE-CREATION VALIDATION (MANDATORY):**

**üö® YOU CANNOT CREATE THIS SEQUENCE DIAGRAM UNTIL:**

1. ‚úÖ **Step 4 (Data Dependency Graph)** is COMPLETE and DOCUMENTED in Phase 1 document
   - Phase 1 document MUST contain section "Data Dependency Graph (Step 4)"
   - If missing ‚Üí **STOP** ‚Üí Complete Step 4 ‚Üí Then proceed

2. ‚úÖ **Step 5 (Control Flow Graph)** is COMPLETE and DOCUMENTED in Phase 1 document
   - Phase 1 document MUST contain section "Control Flow Graph (Step 5)"
   - If missing ‚Üí **STOP** ‚Üí Complete Step 5 ‚Üí Then proceed

3. ‚úÖ **Step 7 (Decision Analysis)** is COMPLETE and DOCUMENTED in Phase 1 document
   - Phase 1 document MUST contain section "Decision Shape Analysis (Step 7)"
   - All self-check answers from Step 7 MUST be shown with YES answers
   - If missing ‚Üí **STOP** ‚Üí Complete Step 7 ‚Üí Then proceed

4. ‚úÖ **Step 8 (Branch Analysis)** is COMPLETE and DOCUMENTED in Phase 1 document
   - Phase 1 document MUST contain section "Branch Shape Analysis (Step 8)"
   - All self-check answers from Step 8 MUST be shown with YES answers
   - If missing ‚Üí **STOP** ‚Üí Complete Step 8 ‚Üí Then proceed

5. ‚úÖ **Step 9 (Execution Order)** is COMPLETE and DOCUMENTED in Phase 1 document
   - Phase 1 document MUST contain section "Execution Order (Step 9)"
   - All self-check answers from Step 9 MUST be shown with YES answers
   - If missing ‚Üí **STOP** ‚Üí Complete Step 9 ‚Üí Then proceed

**VALIDATION CHECKLIST (MUST VERIFY BEFORE CREATING SEQUENCE DIAGRAM):**

Before creating sequence diagram, verify Phase 1 document contains:
- [ ] Section "Data Dependency Graph (Step 4)" - **MUST EXIST AND BE COMPLETE**
- [ ] Section "Control Flow Graph (Step 5)" - **MUST EXIST AND BE COMPLETE**
- [ ] Section "Decision Shape Analysis (Step 7)" - **MUST EXIST AND BE COMPLETE**
- [ ] Section "Branch Shape Analysis (Step 8)" - **MUST EXIST AND BE COMPLETE**
- [ ] Section "Execution Order (Step 9)" - **MUST EXIST AND BE COMPLETE**
- [ ] All self-check answers from Steps 7-9 shown with YES

**IF ANY MISSING OR INCOMPLETE ‚Üí STOP ‚Üí Complete missing steps ‚Üí Show in Phase 1 ‚Üí Then create sequence diagram**

**üõë REQUIRED FORMAT: Operation calls and decisions must be shown explicitly**

**REQUIRED**: Sequence diagram MUST reference:
- "Based on dependency graph in Step 4..."
- "Based on decision analysis in Step 7..."
- "Based on control flow graph in Step 5..."
- "Based on branch analysis in Step 8..."
- "Based on execution order in Step 9..."

**IF NO REFERENCES ‚Üí Sequence diagram created incorrectly ‚Üí WRONG**

```
## Sequence Diagram

**üìã NOTE:** Detailed request/response JSON examples are documented in:
- **Section 16: HTTP Status Codes and Return Path Responses** - For response JSON with populated fields for return paths
- **Section 17: Request/Response JSON Examples** - For detailed request/response JSON examples

START
  |
  ‚îú‚îÄ‚Üí Operation1: [Operation Name] (Downstream)
  |     ‚îî‚îÄ‚Üí READS: [list of properties read]
  |     ‚îî‚îÄ‚Üí WRITES: [list of properties written]
  |     ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 400/404/500]
  |
  ‚îú‚îÄ‚Üí Operation2: [Operation Name] (Downstream)
  |     ‚îî‚îÄ‚Üí READS: [list of properties read]
  |     ‚îî‚îÄ‚Üí WRITES: [list of properties written]
  |     ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 400/404/500]
  |
  ‚îú‚îÄ‚Üí Decision: [Decision Condition]
  |     ‚îú‚îÄ‚Üí IF TRUE ‚Üí Operation3: [Operation Name] (Downstream)
  |     |     ‚îî‚îÄ‚Üí READS: [properties]
  |     |     ‚îî‚îÄ‚Üí WRITES: [properties]
  |     |     ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 400/404/500]
  |     |
  |     ‚îî‚îÄ‚Üí IF FALSE ‚Üí Return Documents [HTTP: 400] [Error Code: ERR_001] [EARLY EXIT]
  |
  ‚îî‚îÄ‚Üí Return Documents [HTTP: 200] [Success Code: SUCCESS_001] [SUCCESS]

**CRITICAL RULES:**
1. Each operation MUST show what it READS and WRITES
2. Each operation MUST show HTTP status codes (Expected success codes and Error codes)
3. Downstream operations MUST be marked: (Downstream)
4. Decisions MUST show both TRUE and FALSE paths
5. Each return path MUST show HTTP status code
6. Each return path MUST show error/success codes
7. Check-before-create patterns MUST show: Check Operation ‚Üí Decision ‚Üí Create Operation (only if check found nothing)
8. Early exits MUST be marked: [EARLY EXIT] with HTTP status code and error code
9. Conditional execution MUST be marked: [Only if condition X]
10. Detailed request/response JSON examples are documented in Section 16 and Section 17 (NOT in this diagram)
```

**Example Format:**

```
START
  |
  ‚îú‚îÄ‚Üí OperationA: Authenticate (Downstream)
  |     ‚îî‚îÄ‚Üí READS: [process.Property_Username, process.Property_Password]
  |     ‚îî‚îÄ‚Üí WRITES: [process.Property_SessionId]
  |     ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 401/500]
  |
  ‚îú‚îÄ‚Üí OperationB: GetEntity (Downstream)
  |     ‚îî‚îÄ‚Üí READS: [process.Property_EntityId, process.Property_SessionId]
  |     ‚îî‚îÄ‚Üí WRITES: [process.Property_EntityExists]
  |     ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 404/500]
  |
  ‚îú‚îÄ‚Üí Decision: process.Property_EntityExists equals ""?
  |     ‚îú‚îÄ‚Üí IF TRUE (NOT exists) ‚Üí OperationC: CreateEntity (Downstream)
  |     |     ‚îî‚îÄ‚Üí READS: [process.Property_EntityId, process.Property_SessionId]
  |     |     ‚îî‚îÄ‚Üí WRITES: [process.Property_CreatedEntityId]
  |     |     ‚îî‚îÄ‚Üí HTTP: [Expected: 201, Error: 400/500]
  |     |
  |     ‚îî‚îÄ‚Üí IF FALSE (EXISTS) ‚Üí Return Documents [HTTP: 200] [Error Code: ENT_ALREADY_EXISTS] [EARLY EXIT]
  |
  ‚îî‚îÄ‚Üí Return Documents [HTTP: 201] [Success Code: ENT_CREATED] [SUCCESS]

**Note:** Detailed request/response JSON examples for all operations and return paths are documented in Section 16 (HTTP Status Codes and Return Path Responses) and Section 17 (Request/Response JSON Examples).
```

---

## üö® CRITICAL PATTERNS (MUST RECOGNIZE)

### Pattern 1: Check-Before-Create (MANDATORY)

**Identification:**
- Operation that checks existence (GetEntity, QueryEntity, CheckEntityExists)
- Followed by Decision checking if result is empty
- If empty ‚Üí Continue to Create operation
- If not empty ‚Üí Early exit (Return Documents)

**Execution Rule:**
- **Check operation MUST execute BEFORE create operation**
- **If check finds entity ‚Üí Skip ALL creation operations**

**Sequence Format:**
```
Operation_Check: Check if entity exists (Downstream)
  ‚îî‚îÄ‚Üí READS: [process.Property_EntityId]
  ‚îî‚îÄ‚Üí WRITES: [process.Property_EntityExists]
  ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 404/500]
  |
  ‚îú‚îÄ‚Üí Decision: process.Property_EntityExists equals "" (empty)?
  |     ‚îú‚îÄ‚Üí IF TRUE (empty = NOT exists) ‚Üí Operation_Create: Create entity (Downstream)
  |     |     ‚îî‚îÄ‚Üí READS: [process.Property_EntityId]
  |     |     ‚îî‚îÄ‚Üí WRITES: [process.Property_CreatedEntityId]
  |     |     ‚îî‚îÄ‚Üí HTTP: [Expected: 201, Error: 400/500]
  |     |
  |     ‚îî‚îÄ‚Üí IF FALSE (has value = EXISTS) ‚Üí Return Documents [HTTP: 200] [Error Code: ENT_ALREADY_EXISTS] [EARLY EXIT]

**Note:** Detailed request/response JSON examples for these operations and return paths are documented in Section 16 (HTTP Status Codes and Return Path Responses) and Section 17 (Request/Response JSON Examples).
```

### Pattern 2: Topological Sort for Branch Paths (MANDATORY)

**When Required:**
- Branch shape with multiple paths
- Paths have data dependencies (Path_A writes Property_X, Path_B reads Property_X)

**Algorithm:**
```
1. Build dependency graph:
   path_dependencies = {}
   FOR EACH path_A:
     FOR EACH path_B:
       IF path_B reads property that path_A writes:
         path_dependencies[path_A].append(path_B)

2. Topological sort:
   sorted_paths = []
   paths_with_no_deps = [paths with no incoming dependencies]
   
   WHILE paths_with_no_deps is not empty:
     current = paths_with_no_deps.pop()
     sorted_paths.append(current)
     
     FOR EACH dependent_path in path_dependencies[current]:
       Remove dependency from dependent_path
       IF dependent_path has no more dependencies:
         paths_with_no_deps.append(dependent_path)
   
   IF len(sorted_paths) != total_paths:
     ERROR: Circular dependency detected

3. Execute paths in sorted_paths order
```

### Pattern 3: Early Exit Detection (MANDATORY)

**Identification:**
- Decision shape where TRUE or FALSE path leads to Return Documents
- This path terminates execution early

**Documentation Rule:**
- **MUST mark as [EARLY EXIT] in sequence diagram**
- **MUST document: "If condition X, skip all subsequent operations"**

### Pattern 4: Subprocess Return Paths (MANDATORY)

**Identification:**
- ProcessCall shape with returnpaths array
- Subprocess has multiple Return Documents shapes with different labels

**Analysis Steps:**
1. **Trace subprocess internal flow** - From START to all Return Documents
2. **Map return labels** - Each return label maps to different main process path
3. **Identify success vs error paths** - Success = Stop(continue=true), Error = Return Documents with error label

**Execution Rule:**
- **Subprocess executes completely before main process continues**
- **Return label determines which main process path executes next**

**Sequence Format:**
```
Main Process:
  ‚îú‚îÄ‚Üí ProcessCall: Call Subprocess_Auth
  |     ‚îî‚îÄ‚Üí SUBPROCESS INTERNAL FLOW:
  |           ‚îú‚îÄ‚Üí START
  |           ‚îú‚îÄ‚Üí Build Request
  |           ‚îú‚îÄ‚Üí Operation_Auth (Downstream)
  |           |     ‚îî‚îÄ‚Üí HTTP: [Expected: 200, Error: 401/500]
  |           ‚îú‚îÄ‚Üí Decision: Status Code "20*"?
  |           |     ‚îú‚îÄ‚Üí IF TRUE ‚Üí Extract Property_SessionId ‚Üí Stop (continue=true) [SUCCESS RETURN] [HTTP: 200]
  |           |     |     ‚îî‚îÄ‚Üí Response: { "sessionId": "abc123", "expiresAt": "..." }
  |           |     ‚îî‚îÄ‚Üí IF FALSE ‚Üí Return Documents ("Error_Label") [ERROR RETURN] [HTTP: 401]
  |           |           ‚îî‚îÄ‚Üí Response: { "errorCode": "AUTH_FAILED", "message": "Invalid credentials" }
  |           ‚îî‚îÄ‚Üí END SUBPROCESS
  |
  ‚îú‚îÄ‚Üí Decision: Subprocess returned "Error_Label"?
  |     ‚îú‚îÄ‚Üí IF TRUE ‚Üí Return Documents [HTTP: 401] [EARLY EXIT]
  |     |     ‚îî‚îÄ‚Üí Response: { "errorCode": "AUTH_FAILED", "message": "Authentication failed" }
  |     ‚îî‚îÄ‚Üí IF FALSE ‚Üí Continue (Property_SessionId available)
```

### Pattern 5: Nested Branches and Decisions (EDGE CASE)

**Identification:**
- Branch shape inside another branch path
- Decision shape inside branch path
- Multiple levels of nesting

**Analysis Rule:**
- **Analyze inner structures FIRST, then outer**
- **Inner branch/decision dependencies affect outer path dependencies**
- **Document nesting levels explicitly**

### Pattern 6: Loops and Iterations (EDGE CASE)

**Identification:**
- Shape with dragpoint pointing back to earlier shape
- Cycle detected in control flow graph

**Analysis Rule:**
- **Loops are rare in Boomi (usually handled by connectors)**
- **If cycle detected: Document loop condition and exit condition**
- **Loop must have termination condition (decision ‚Üí exit)**

### Pattern 7: Property Chains (EDGE CASE)

**Identification:**
- Property_A written by Shape1
- Property_B written by Shape2, reads Property_A
- Property_C written by Shape3, reads Property_B

**Analysis Rule:**
- **Build transitive dependency graph**
- **Chain: Shape1 ‚Üí Shape2 ‚Üí Shape3 (must execute in order)**

---

## üìã VALIDATION CHECKLIST (MANDATORY)

### Data Dependencies
- [ ] All property WRITES identified
- [ ] All property READS identified
- [ ] Dependency graph built
- [ ] Execution order satisfies all dependencies (no read-before-write)

### Decision Analysis
- [ ] ALL decision shapes inventoried
- [ ] BOTH TRUE and FALSE paths traced to termination
- [ ] Pattern type identified for each decision
- [ ] Early exits identified and documented
- [ ] Convergence points identified (if paths rejoin)

### Branch Analysis
- [ ] Each branch classified as parallel or sequential
- [ ] **üö® CRITICAL**: If branch contains API calls ‚Üí Classification is ALWAYS SEQUENTIAL
- [ ] **SELF-CHECK:** Did I check for API calls in branch paths? (Must answer: YES)
- [ ] **SELF-CHECK:** Did I classify or assume? (Must answer: Classified)
- [ ] If sequential: dependency_order built using topological sort OR sequential order (if API calls)
- [ ] Each path traced to terminal point
- [ ] Convergence points identified
- [ ] Execution continuation point determined

### Sequence Diagram
- [ ] Format follows required structure (Operation ‚Üí Decision ‚Üí Operation)
- [ ] Each operation shows READS and WRITES
- [ ] Decisions show both TRUE and FALSE paths
- [ ] **CRITICAL:** Check-before-create patterns shown correctly
- [ ] **SELF-CHECK:** Did I verify check happens BEFORE create? (Must answer: YES)
- [ ] **CROSS-VALIDATION:** Sequence diagram matches control flow graph from Step 5
- [ ] **CROSS-VALIDATION:** Execution order matches dependency graph from Step 4
- [ ] Early exits marked [EARLY EXIT]
- [ ] Conditional execution marked [Only if condition X]
- [ ] Subprocess internal flows documented
- [ ] Subprocess return paths mapped to main process

### Subprocess Analysis
- [ ] ALL subprocesses analyzed (internal flow traced)
- [ ] Return paths identified (success and error)
- [ ] Return path labels mapped to main process shapes
- [ ] Properties written by subprocess documented
- [ ] Properties read by subprocess from main process documented

### Edge Cases
- [ ] Nested branches/decisions analyzed
- [ ] Loops identified (if any) with exit conditions
- [ ] Property chains traced (transitive dependencies)
- [ ] Circular dependencies detected and resolved
- [ ] Try/Catch error paths documented

### Property Extraction Completeness
- [ ] All property patterns searched (${}, %%, {})
- [ ] Message parameters checked for process properties
- [ ] Operation headers/path parameters checked
- [ ] Decision track properties identified (meta.*)
- [ ] Document properties that read other properties identified

### Input/Output Structure Analysis (CONTRACT VERIFICATION)
- [ ] Entry point operation identified
- [ ] Request profile identified and loaded
- [ ] Request profile structure analyzed (JSON/XML)
- [ ] Array vs single object detected
- [ ] Array cardinality documented (minOccurs, maxOccurs)
- [ ] ALL request fields extracted (including nested structures)
- [ ] Request field paths documented (full Boomi paths)
- [ ] Request field mapping table generated (Boomi ‚Üí Azure DTO)
- [ ] Response profile identified and loaded
- [ ] Response profile structure analyzed
- [ ] ALL response fields extracted
- [ ] Response field mapping table generated
- [ ] Document processing behavior determined (splitting vs batch)
- [ ] Input/Output structure documented in Phase 1 document (Section 13 & 14)

### HTTP Status Codes and Return Path Responses (NEW - MANDATORY)
- [ ] Section 16 (HTTP Status Codes and Return Path Responses - Step 1e) present
- [ ] All return paths documented with HTTP status codes
- [ ] Response JSON examples provided for each return path
- [ ] Populated fields documented for each return path (source and populated by)
- [ ] Decision conditions leading to each return documented
- [ ] Error codes and success codes documented for each return path
- [ ] Downstream operation HTTP status codes documented (expected success and error codes)
- [ ] Error handling strategy documented for downstream operations

### Request/Response JSON Examples (NEW - MANDATORY)
- [ ] Section 17 (Request/Response JSON Examples) present
- [ ] Process Layer entry point request JSON example provided
- [ ] Process Layer response JSON examples provided (all return paths)
- [ ] Downstream System Layer request JSON examples provided (all operations)
- [ ] Downstream System Layer response JSON examples provided (all operations - success and error scenarios)

### Map Analysis (NEW - MANDATORY)
- [ ] ALL map files identified and loaded
- [ ] SOAP request maps identified (maps to operation request profiles)
- [ ] Field mappings extracted from each map
- [ ] Profile vs map field name discrepancies documented
- [ ] Map field names marked as AUTHORITATIVE for SOAP envelopes
- [ ] Scripting functions analyzed (date formatting, concatenation, etc.)
- [ ] Static values identified and documented
- [ ] Process property mappings documented
- [ ] Element names extracted and documented (dto, breakdownTaskDto, locationDto, etc.)
- [ ] Namespace prefixes verified from message shapes
- [ ] Map Analysis documented in Phase 1 document (Section 15)

---

## üö´ NEVER ASSUME

**üîç MANDATORY SELF-CHECK before declaring extraction complete:**

1. **NEVER assume Branch = Parallel** - Check data dependencies AND API calls first
   - **üö® CRITICAL**: If branch contains API calls ‚Üí ALWAYS SEQUENTIAL (no parallel API calls)
   - **SELF-CHECK:** Did I check dependencies AND API calls? (Answer: YES/NO)
   
2. **NEVER assume visual order = execution order** - Use data dependencies
   - **SELF-CHECK:** Did I use dependency graph? (Answer: YES/NO)
   
3. **NEVER skip decision analysis** - It's BLOCKING
   - **SELF-CHECK:** Did I trace BOTH paths? (Answer: YES/NO)
   
4. **NEVER assume existence checks happen after creation** - They happen BEFORE
   - **SELF-CHECK:** Did I verify check-before-create? (Answer: YES/NO)
   
5. **NEVER skip topological sort** - If dependencies exist, sort is MANDATORY
   - **SELF-CHECK:** Did I apply topological sort? (Answer: YES/NO)
   
6. **NEVER ignore early exits** - They change entire flow
   - **SELF-CHECK:** Did I document all early exits? (Answer: YES/NO)
   
7. **NEVER assume convergence** - Check reverse flow mapping
   - **SELF-CHECK:** Did I check reverse flow? (Answer: YES/NO)
   
8. **NEVER skip property analysis** - It reveals true dependencies
   - **SELF-CHECK:** Did I extract all reads/writes? (Answer: YES/NO)
   
9. **NEVER treat subprocesses as black boxes** - Trace internal flow
   - **SELF-CHECK:** Did I trace subprocess flow? (Answer: YES/NO)
   
10. **NEVER assume single return path** - Subprocesses can have multiple returns
    - **SELF-CHECK:** Did I check all return paths? (Answer: YES/NO)
    
11. **NEVER skip property pattern variations** - Check ${}, %%, {}, and parameter arrays
    - **SELF-CHECK:** Did I check all patterns? (Answer: YES/NO)
    
12. **NEVER ignore nested structures** - Analyze inner before outer
    - **SELF-CHECK:** Did I analyze nested structures? (Answer: YES/NO)
    
13. **NEVER assume single object input** - ALWAYS check for arrays in request profile
    - **SELF-CHECK:** Did I check for arrays? (Answer: YES/NO)
    
14. **NEVER skip input structure analysis** - DTOs MUST exactly match Boomi contracts
    - **SELF-CHECK:** Did I complete input structure analysis? (Answer: YES/NO)
    
15. **NEVER assume field names** - Extract exact field names and paths from profiles
    - **SELF-CHECK:** Did I extract from profiles? (Answer: YES/NO)
    
16. **NEVER skip array cardinality** - minOccurs/maxOccurs determine required vs optional
    - **SELF-CHECK:** Did I document cardinality? (Answer: YES/NO)
    
17. **NEVER assume document processing** - Analyze inputType to determine splitting behavior
    - **SELF-CHECK:** Did I analyze inputType? (Answer: YES/NO)

18. **NEVER use profile field names for SOAP envelopes without checking maps** - Profiles define schema, maps show actual usage
    - **SELF-CHECK:** Did I analyze maps to verify field names? (Answer: YES/NO)
    - **CRITICAL:** Map field names are AUTHORITATIVE, profile field names are reference only

19. **NEVER skip map analysis** - Maps reveal actual field names, data transformations, and scripting logic
    - **SELF-CHECK:** Did I check ALL maps for SOAP request operations? (Answer: YES/NO)

20. **NEVER assume profile field names match SOAP request field names** - They often differ (BDET_FKEY_CAT_SEQ vs CategoryId)
    - **SELF-CHECK:** Did I compare profile vs map field names? (Answer: YES/NO)

**üõë FINAL GATE:** If ANY self-check answer is NO ‚Üí STOP, complete that step correctly before proceeding

**üö® EXPLICIT ENFORCEMENT - VALIDATION CHECKPOINT:**

**Before declaring extraction complete, you MUST verify Phase 1 document contains:**

**CRITICAL SECTIONS (MUST EXIST AND BE COMPLETE):**
- [ ] Section "Input Structure Analysis (Step 1a)" - **CANNOT SKIP - Required before Phase 2**
- [ ] Section "Response Structure Analysis (Step 1b)" - **CANNOT SKIP - Required before Phase 2**
- [ ] Section "Operation Response Analysis (Step 1c)" - **CANNOT SKIP - Required before Step 7**
- [ ] Section "Map Analysis (Step 1d)" - **CANNOT SKIP - Required before Phase 2** ‚ö†Ô∏è **NEW MANDATORY**
- [ ] Section "Process Properties Analysis (Steps 2-3)" - **Required for Step 4**
- [ ] Section "Data Dependency Graph (Step 4)" - **CANNOT SKIP**
- [ ] Section "Control Flow Graph (Step 5)" - **Required for flow understanding**
- [ ] Section "Decision Shape Analysis (Step 7)" - **CANNOT SKIP - Must include data source analysis**
- [ ] Section "Branch Shape Analysis (Step 8)" - **CANNOT SKIP**
- [ ] Section "Execution Order (Step 9)" - **CANNOT SKIP - Must include business logic verification**
- [ ] Section "Sequence Diagram (Step 10)" - **Only after sections 3, 4, 5, 6, 7 complete** (Decision, Dependency, Control Flow, Branch, Execution Order)

**SELF-CHECK ANSWERS (MUST BE SHOWN):**
- [ ] All Step 7 self-check answers shown in Phase 1 document with YES answers
- [ ] All Step 8 self-check answers shown in Phase 1 document with YES answers
- [ ] All Step 9 self-check answers shown in Phase 1 document with YES answers

**VALIDATION:**
- [ ] Sequence diagram references Step 4 (dependency graph)
- [ ] Sequence diagram references Step 5 (control flow graph)
- [ ] Sequence diagram references Step 7 (decision analysis)
- [ ] Sequence diagram references Step 8 (branch analysis)
- [ ] Sequence diagram references Step 9 (execution order)

**IF ANY MISSING ‚Üí Extraction NOT complete ‚Üí CANNOT proceed to Phase 2**

---

## üõë ERROR PREVENTION PROTOCOL

**If an error is discovered in extraction:**

1. **STOP** - Do not continue with extraction
2. **IDENTIFY** - Which step was skipped or done incorrectly
3. **REDO** - Complete that step correctly following the rulebook
4. **REVALIDATE** - Complete all validation checklists again
5. **DOCUMENT** - Note the error and correction

**Before declaring extraction complete, verify:**
- [ ] All Steps 1-10 completed in order
- [ ] All validation checklists completed
- [ ] All "NEVER ASSUME" self-checks answered YES
- [ ] Sequence diagram cross-checked against JSON dragpoints
- [ ] Execution order verified against dependency graph

**If ANY item is missing ‚Üí Extraction is NOT complete**

---

## üîç EDGE CASE HANDLING

### Edge Case 1: Circular Dependencies

**Detection:**
```
IF topological_sort fails (len(sorted_paths) != total_paths):
  ERROR: Circular dependency detected
  ACTION: Review dependency graph for cycles
  SOLUTION: One dependency must be broken (likely design issue)
```

### Edge Case 2: Missing Property Writers

**Detection:**
```
FOR EACH property in property_reads:
  IF property not in property_writes:
    CHECK:
      - Is property input parameter? (from process trigger)
      - Is property written in subprocess? (check subprocess analysis)
      - Is property set by connector? (check connection settings)
      - Is property missing? (ERROR - must be fixed)
```

### Edge Case 3: Decision Without Both Paths

**Detection:**
```
FOR EACH decision shape:
  IF missing true dragpoint OR missing false dragpoint:
    ERROR: Incomplete decision shape
    ACTION: Document as incomplete, note which path is missing
```

### Edge Case 4: Branch Path Without Terminal

**Detection:**
```
FOR EACH branch path:
  terminal = trace_to_termination(path[0])
  IF terminal.type == "rejoins" AND no convergence point found:
    WARNING: Path may loop or be incomplete
    ACTION: Check for cycles or missing terminal shapes
```

### Edge Case 5: Subprocess Without Return Paths

**Detection:**
```
FOR EACH subprocess:
  IF no Return Documents AND no Stop(continue=true):
    ERROR: Subprocess has no return mechanism
    ACTION: Check if subprocess is incomplete or uses exception
```

---

## üìö JSON STRUCTURE REFERENCE

### Property WRITE (from API response)
```json
{
  "shapeId": "shapeX",
  "shapetype": "documentproperties",
  "documentproperties": {
    "propertyassignments": [{
      "propertyId": "process.Property_X",
      "sourcevalues": [{
            "valueType": "profile",
            "profileElementId": "elem_123",
        "profileId": "profile-guid"
      }]
    }]
  }
}
```
**Extraction:** shapeX WRITES process.Property_X from profile element

### Property READ (in operation request)
```json
{
  "shapeId": "shapeX",
  "shapetype": "connectoraction",
  "connectoraction": {
    "operationId": "operation_abc"
  }
}
```
**Operation JSON:**
```json
{
  "componentId": "operation_abc",
  "request": {
    "body": "<GetEntity><EntityID>${process.Property_EntityID}</EntityID></GetEntity>"
  }
}
```
**Extraction:** shapeX READS process.Property_EntityID (used in request body)

### Decision Shape
```json
{
  "shapeId": "shapeX",
  "shapetype": "decision",
  "decision": {
    "comparison": "equals",
    "decisionvalue": [{
        "valueType": "profile",
        "profileElementId": "elem_456"
    }, {
        "valueType": "static",
        "value": ""
    }]
  },
  "dragpoints": [{
      "identifier": "true",
      "toShape": "shapeY"
  }, {
      "identifier": "false",
      "toShape": "shapeZ"
  }]
}
```
**Extraction:** shapeX compares profile element to empty string, TRUE‚ÜíshapeY, FALSE‚ÜíshapeZ

### Branch Shape
```json
{
  "shapeId": "shapeX",
  "shapetype": "branch",
  "branch": {
    "numBranches": "6"
  },
  "dragpoints": [{
    "identifier": "1",
    "toShape": "shapeY"
  }, {
    "identifier": "2",
    "toShape": "shapeZ"
  }]
}
```
**Extraction:** shapeX is 6-path branch, Path1‚ÜíshapeY, Path2‚ÜíshapeZ

### ProcessCall (Subprocess) Shape
```json
{
  "shapeId": "shapeX",
  "shapetype": "processcall",
  "processcall": {
    "processId": "subprocess_guid_abc",
    "returnpaths": [{
      "returnpaths": [{
        "returnLabel": "Error_Label",
        "childShapeName": "shapeY"
      }]
    }]
  },
  "dragpoints": [{
    "identifier": "shapeY",
    "text": "Error_Label",
    "toShape": "shapeY"
  }]
}
```
**Extraction:** shapeX calls subprocess_guid_abc, if subprocess returns "Error_Label" ‚Üí goes to shapeY, otherwise continues normally

### Try/Catch Shape
```json
{
  "shapeId": "shapeX",
  "shapetype": "catcherrors",
  "dragpoints": [{
    "identifier": "default",
    "text": "Try",
    "toShape": "shapeY"
  }, {
    "identifier": "error",
    "text": "Catch",
    "toShape": "shapeZ"
  }]
}
```
**Extraction:** shapeX wraps Try path (shapeY) and Catch path (shapeZ), if any error in Try ‚Üí jumps to Catch

### Stop Shape (Continue)
```json
{
  "shapeId": "shapeX",
  "shapetype": "stop",
  "stop": {
    "continue": "true"
  },
  "dragpoints": []
}
```
**Extraction:** shapeX is Stop with continue=true, execution continues (used in subprocesses to return data)

### Stop Shape (Terminate)
```json
{
  "shapeId": "shapeX",
  "shapetype": "stop",
  "stop": {
    "continue": "false"
  },
  "dragpoints": []
}
```
**Extraction:** shapeX is Stop with continue=false, process terminates here

### Return Documents Shape
```json
{
  "shapeId": "shapeX",
  "shapetype": "returndocuments",
  "returndocuments": {
    "label": "Return Documents"
  },
  "dragpoints": []
}
```
**Extraction:** shapeX returns documents to caller, process ends (no dragpoints = terminal)

---

## üìã PHASE 1 DOCUMENT STRUCTURE (MANDATORY SECTIONS)

**üö® CRITICAL ENFORCEMENT: These sections MUST be created in order. You CANNOT skip sections or create later sections before earlier ones are complete.**

**Every Phase 1 document MUST include these sections in this exact order:**

1. **Operations Inventory** - All operations listed
2. **Process Properties Analysis** - All properties WRITTEN and READ
3. **Decision Shape Analysis (Step 7)** - All decisions with TRUE/FALSE paths
   - **üõë CRITICAL**: This section MUST exist before creating Sequence Diagram
   - **üõë CRITICAL**: Must show all self-check answers from Step 7
4. **Data Dependency Graph (Step 4)** - Dependency chains documented
   - **üõë CRITICAL**: This section MUST exist before creating Sequence Diagram
5. **Control Flow Graph (Step 5)** - Dragpoint connections mapped
6. **Branch Shape Analysis (Step 8)** - All branches classified
   - **üõë CRITICAL**: This section MUST exist before creating Sequence Diagram
   - **üõë CRITICAL**: Must show all self-check answers from Step 8
   - **üõë CRITICAL**: Must show dependency graph, classification, topological sort
7. **Execution Order (Step 9)** - True execution sequence
   - **üõë CRITICAL**: This section MUST exist before creating Sequence Diagram
   - **üõë CRITICAL**: Must show all self-check answers from Step 9
   - **üõë CRITICAL**: Must reference Step 4 (dependency graph) and Step 8 (branch analysis)
8. **Sequence Diagram (Step 10)** - Visual flow representation
   - **üõë CRITICAL**: CANNOT CREATE until sections 3, 4, 5, 6, 7 are complete
   - **üõë CRITICAL**: Must reference sections 3, 4, 5, 6, 7 in the diagram
9. **Subprocess Analysis** - Internal flows traced
10. **Critical Patterns Identified** - Check-before-create, etc.
11. **Validation Checklist** - All items checked
12. **System Layer Identification** - Third-party systems identified
13. **Input Structure Analysis** - ‚ö†Ô∏è **NEW MANDATORY SECTION**
14. **Field Mapping Analysis** - ‚ö†Ô∏è **NEW MANDATORY SECTION**
15. **Map Analysis (Step 1d)** - ‚ö†Ô∏è **NEW MANDATORY SECTION** - SOAP request field mappings
   - **üõë CRITICAL**: This section MUST exist before Phase 2 (SOAP envelope creation)
   - **üõë CRITICAL**: Must show profile vs map field name discrepancies

**üö® ENFORCEMENT CHECKPOINT BEFORE SECTION 8 (Sequence Diagram):**

Before creating section 8 (Sequence Diagram), you MUST verify:
- [ ] Section 3 (Decision Shape Analysis - Step 7) exists and is complete
- [ ] Section 4 (Data Dependency Graph - Step 4) exists and is complete
- [ ] Section 5 (Control Flow Graph - Step 5) exists and is complete (includes Step 6 reverse flow)
- [ ] Section 6 (Branch Shape Analysis - Step 8) exists and is complete
- [ ] Section 7 (Execution Order - Step 9) exists and is complete
- [ ] All self-check answers from Steps 7-9 are shown in their respective sections

**IF ANY MISSING OR INCOMPLETE ‚Üí STOP ‚Üí Complete missing sections ‚Üí Then create Sequence Diagram**

### Section 13: Input Structure Analysis (MANDATORY)

**Must Include:**
- Request profile ID and name
- Profile type (JSON/XML)
- Root structure path
- Array detection (isArray: true/false)
- Array cardinality (minOccurs, maxOccurs)
- Complete JSON/XML structure example
- Document processing behavior
- Field count (total fields including nested)

**Example Format:**
```markdown
## 13. Input Structure Analysis

### Request Profile Structure
- **Profile ID:** [profile-guid]
- **Profile Name:** [RequestProfileName]
- **Profile Type:** profile.json
- **Root Structure:** Root/Object/entityArray/Array/ArrayElement1/Object/...
- **Array Detection:** ‚úÖ YES - entityArray is an array
- **Array Cardinality:** 
  - minOccurs: 0
  - maxOccurs: -1 (unlimited)
- **Input Type:** singlejson

### Input Format
[Complete JSON structure]

### Document Processing Behavior
- **Boomi Processing:** Each array element triggers separate process execution
- **Azure Function Requirement:** Must accept array and process each element
- **Implementation Pattern:** Loop through array, process each work order, aggregate results
```

### Section 14: Field Mapping Analysis (MANDATORY)

**Must Include:**
- Complete field mapping table (Boomi ‚Üí Azure DTO)
- All fields from request profile
- All fields from response profile
- Nested structures documented
- Required vs optional fields identified

**Example Format:**
```markdown
## 14. Field Mapping Analysis

### Request Field Mapping

| Boomi Field Path | Boomi Field Name | Data Type | Required | Azure DTO Property | Notes |
|------------------|------------------|-----------|----------|-------------------|-------|
| Root/Object/entityArray/Array/ArrayElement1/Object/field1 | field1 | character | Yes | Field1 | Used in OperationA |
| Root/Object/entityArray/Array/ArrayElement1/Object/field2 | field2 | character | Yes | Field2 | Used in OperationB |
| ... | ... | ... | ... | ... | ... |

### Response Field Mapping

| Boomi Field Path | Boomi Field Name | Data Type | Azure DTO Property | Notes |
|------------------|------------------|-----------|-------------------|-------|
| ... | ... | ... | ... | ... |
```

**Validation:**
- [ ] Section 13 (Input Structure Analysis) present
- [ ] Section 14 (Field Mapping Analysis) present
- [ ] All request fields mapped
- [ ] All response fields mapped
- [ ] Array structures documented
- [ ] Nested structures documented

### Section 15: Map Analysis (MANDATORY - NEW)

**Must Include:**
- Map inventory (all map files with IDs and names)
- SOAP request map identification (which maps target operation request profiles)
- Complete field mappings for each SOAP request map
- Profile vs map field name comparison table
- Scripting function analysis (date formatting, concatenation, etc.)
- Static value identification
- Process property mappings
- Element names extracted and documented (dto, breakdownTaskDto, locationDto, etc.)
- Namespace prefixes verified from message shapes

**Example Format:**
```markdown
## 15. Map Analysis (Step 1d)

### SOAP Request Maps Inventory

| Map ID | Map Name | From Profile | To Profile | Operation |
|---|---|---|---|---|
| 390614fd | CreateBreakdownTask EQ+_to_CAFM_Create | af096014 | 362c3ec8 | CreateBreakdownTask |

### Map: CreateBreakdownTask (390614fd)

**From Profile:** af096014 (EQ+_CAFM_Create_Request)  
**To Profile:** 362c3ec8 (CreateBreakdownTask Request)  
**Type:** SOAP Request Map

**Element Names (CRITICAL):**
- Operation Element: CreateBreakdownTask
- DTO Element: breakdownTaskDto
- **RULE:** Use "breakdownTaskDto" in SOAP envelope, NOT generic "dto"

**Namespace Prefixes (CRITICAL):**
- Namespace Declarations: fsi1: Fsi.Concept.Contracts.Entities.ServiceModel
- Field Prefix: CategoryId ‚Üí fsi1:
- **RULE:** All fields in this operation use fsi1: prefix

**Field Mappings:**

| Source Field | Source Type | Target Field (SOAP) | Profile Field Name | Discrepancy? |
|---|---|---|---|---|
| reporterName | profile | ReporterName | ReporterName | ‚úÖ Match |
| reporterEmail | profile | BDET_EMAIL | BDET_EMAIL | ‚úÖ Match |
| DPP_CategoryId | function (process property) | CategoryId | BDET_FKEY_CAT_SEQ | ‚ùå DIFFERENT |
| DDP_DisciplineId | function (process property) | DisciplineId | BDET_FKEY_LAB_SEQ | ‚ùå DIFFERENT |

**Scripting Functions:**

| Function | Input | Output | Logic |
|---|---|---|---|
| Function 11 | scheduledDate, scheduledTimeStart | ScheduledDateUtc | Combine date+time, format to ISO with .0208713Z suffix |
| Function 13 | raisedDateUtc | RaisedDateUtc | Format to ISO with .0208713Z suffix |

**Profile vs Map Discrepancies:**

| Profile Field Name | Map Field Name (ACTUAL) | Authority | Use in SOAP |
|---|---|---|---|
| BDET_FKEY_CAT_SEQ | CategoryId | ‚úÖ MAP | CategoryId |
| BDET_FKEY_LAB_SEQ | DisciplineId | ‚úÖ MAP | DisciplineId |
| BDET_FKEY_PRI_SEQ | PriorityId | ‚úÖ MAP | PriorityId |

**CRITICAL RULE:** Map field names are AUTHORITATIVE. Use map field names in SOAP envelopes, NOT profile field names.
```

**Validation:**
- [ ] Section 15 (Map Analysis - Step 1d) present
- [ ] All SOAP request maps analyzed
- [ ] Field mappings extracted
- [ ] Profile vs map discrepancies documented
- [ ] Scripting functions analyzed
- [ ] Element names extracted and documented
- [ ] Namespace prefixes verified
- [ ] Map field names marked as authoritative

### Section 16: HTTP Status Codes and Return Path Responses (MANDATORY - NEW)

**Must Include:**
- For each Return Documents shape: Return label, HTTP status code, decision conditions leading to return
- Response JSON example for each return path showing populated fields only
- Source of each populated field (operation response, process property, input field)
- Error codes and success codes for each return path
- HTTP status codes for downstream operations (expected success codes and error codes)

**Example Format:**
```markdown
## 16. HTTP Status Codes and Return Path Responses (Step 1e)

### Return Path 1: Success Return

**Return Label:** "Return Documents"  
**Return Shape ID:** shape_123  
**HTTP Status Code:** 200  
**Decision Conditions Leading to Return:**
- None (default success path)

**Populated Response Fields:**
| Field Name | Field Path | Source | Populated By |
|------------|------------|--------|--------------|
| entityId | Root/Object/entityId | operation_response | CreateEntity |
| status | Root/Object/status | static | "Created" |
| createdAt | Root/Object/createdAt | operation_response | CreateEntity |

**Response JSON Example:**
```json
{
  "entityId": "12345",
  "status": "Created",
  "createdAt": "2024-01-15T10:30:00Z"
}
```

### Return Path 2: Validation Error Return

**Return Label:** "Return Documents"  
**Return Shape ID:** shape_456  
**HTTP Status Code:** 400  
**Decision Conditions Leading to Return:**
- Decision shape_789: process.Property_EntityId equals "" ‚Üí TRUE path

**Error Code:** VAL_001  
**Populated Response Fields:**
| Field Name | Field Path | Source | Populated By |
|------------|------------|--------|--------------|
| errorCode | Root/Object/errorCode | static | "VAL_001" |
| message | Root/Object/message | static | "Entity ID is required" |

**Response JSON Example:**
```json
{
  "errorCode": "VAL_001",
  "message": "Entity ID is required"
}
```

### Downstream Operations HTTP Status Codes

| Operation Name | Expected Success Codes | Error Codes | Error Handling |
|----------------|----------------------|-------------|----------------|
| Authenticate | 200 | 401, 500 | Throw exception on error |
| GetEntity | 200 | 404, 500 | Return empty if 404, throw on 500 |
| CreateEntity | 201 | 400, 500 | Throw exception on error |
```

**Validation:**
- [ ] Section 16 (HTTP Status Codes and Return Path Responses - Step 1e) present
- [ ] All return paths documented with HTTP status codes
- [ ] Response JSON examples provided for each return path
- [ ] Populated fields documented for each return path
- [ ] Downstream operation HTTP status codes documented
- [ ] Error codes and success codes documented

### Section 17: Request/Response JSON Examples (MANDATORY - NEW)

**Must Include:**
- Process Layer entry point request JSON example (actual structure from request profile)
- Process Layer response JSON examples (for each return path)
- Downstream System Layer request JSON examples (for each operation)
- Downstream System Layer response JSON examples (for each operation)

**Example Format:**
```markdown
## 17. Request/Response JSON Examples

### Process Layer Entry Point

**Request JSON Example:**
```json
{
  "entityId": "12345",
  "entityName": "Test Entity",
  "entityType": "TypeA",
  "items": [
    {
      "itemId": "item1",
      "itemName": "Item 1"
    }
  ]
}
```

**Response JSON Examples:**

**Success Response (HTTP 200):**
```json
{
  "entityId": "12345",
  "status": "Created",
  "createdAt": "2024-01-15T10:30:00Z",
  "message": "Entity created successfully"
}
```

**Error Response (HTTP 400):**
```json
{
  "errorCode": "VAL_001",
  "message": "Entity ID is required",
  "errorDetails": {
    "errors": [
      {
        "stepName": "EntityReqDTO.cs / Validate",
        "stepError": "EntityId is Required."
      }
    ]
  }
}
```

### Downstream System Layer Calls

**Operation: Authenticate**

**Request JSON:**
```json
{
  "username": "user@example.com",
  "password": "password123"
}
```

**Response JSON (Success - HTTP 200):**
```json
{
  "sessionId": "abc123xyz",
  "expiresAt": "2024-01-15T11:30:00Z"
}
```

**Response JSON (Error - HTTP 401):**
```json
{
  "errorCode": "AUTH_FAILED",
  "message": "Invalid credentials"
}
```

**Operation: CreateEntity**

**Request JSON:**
```json
{
  "name": "Test Entity",
  "type": "TypeA",
  "locationId": "loc123"
}
```

**Response JSON (Success - HTTP 201):**
```json
{
  "entityId": "12345",
  "status": "Created",
  "createdAt": "2024-01-15T10:30:00Z"
}
```

**Response JSON (Error - HTTP 400):**
```json
{
  "errorCode": "INVALID_REQUEST",
  "message": "Invalid entity type"
}
```
```

**Validation:**
- [ ] Section 17 (Request/Response JSON Examples) present
- [ ] Process Layer request JSON example provided
- [ ] Process Layer response JSON examples provided (all return paths)
- [ ] Downstream System Layer request JSON examples provided (all operations)
- [ ] Downstream System Layer response JSON examples provided (all operations - success and error)

---

## üõë PRE-PHASE 2 VALIDATION GATE (MANDATORY)

**YOU CANNOT PROCEED TO PHASE 2 (CODE GENERATION)** until ALL of the following are complete:

### Phase 1 Completion Checklist

**Input/Output Analysis:**
- [ ] Step 1a (Input Structure Analysis) - COMPLETE and DOCUMENTED
- [ ] Step 1b (Response Structure Analysis) - COMPLETE and DOCUMENTED
- [ ] Step 1c (Operation Response Analysis) - COMPLETE and DOCUMENTED
- [ ] Step 1d (Map Analysis) - COMPLETE and DOCUMENTED
- [ ] **Step 1e (HTTP Status Codes and Return Path Responses) - COMPLETE and DOCUMENTED** ‚ö†Ô∏è **NEW MANDATORY**

**Process Flow Analysis:**
- [ ] Step 2 (Property Writes) - COMPLETE and DOCUMENTED
- [ ] Step 3 (Property Reads) - COMPLETE and DOCUMENTED
- [ ] Step 4 (Data Dependency Graph) - COMPLETE and DOCUMENTED
- [ ] Step 5 (Control Flow Graph) - COMPLETE and DOCUMENTED
- [ ] Step 6 (Reverse Flow Mapping) - COMPLETE and DOCUMENTED
- [ ] Step 7 (Decision Analysis) - COMPLETE and DOCUMENTED
- [ ] Step 8 (Branch Analysis) - COMPLETE and DOCUMENTED
- [ ] Step 9 (Execution Order) - COMPLETE and DOCUMENTED
- [ ] Step 10 (Sequence Diagram) - COMPLETE and DOCUMENTED

**Contract Verification:**
- [ ] Section 13 (Input Structure Analysis) - COMPLETE
- [ ] Section 14 (Field Mapping Analysis) - COMPLETE
- [ ] Section 15 (Map Analysis) - COMPLETE
- [ ] **Section 16 (HTTP Status Codes and Return Path Responses) - COMPLETE** ‚ö†Ô∏è **NEW MANDATORY**
- [ ] **Section 17 (Request/Response JSON Examples) - COMPLETE** ‚ö†Ô∏è **NEW MANDATORY**

**Self-Check Questions:**

1. ‚ùì Did I analyze ALL map files? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Analyze all maps ‚Üí Document in Phase 1

2. ‚ùì Did I identify SOAP request maps? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Identify SOAP request maps ‚Üí Document in Phase 1

3. ‚ùì Did I extract actual field names from maps? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Extract field names from maps ‚Üí Document in Phase 1

4. ‚ùì Did I compare profile field names vs map field names? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Compare and document discrepancies ‚Üí Document in Phase 1

5. ‚ùì Did I mark map field names as AUTHORITATIVE? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Mark map field names as authoritative ‚Üí Document in Phase 1

6. ‚ùì Did I analyze scripting functions in maps? (Answer: YES/NO)
   - **REQUIRED:** YES (if maps contain scripting)
   - If NO ‚Üí **STOP** ‚Üí Analyze scripting functions ‚Üí Document in Phase 1

7. ‚ùì Did I extract element names from maps? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Extract element names ‚Üí Document in Phase 1

8. ‚ùì Did I verify namespace prefixes from message shapes? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Verify namespace prefixes ‚Üí Document in Phase 1

9. ‚ùì Did I extract HTTP status codes for all return paths? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Extract HTTP status codes ‚Üí Document in Phase 1

10. ‚ùì Did I document response JSON for each return path? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Document response JSON ‚Üí Document in Phase 1

11. ‚ùì Did I document populated fields for each return path? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Document populated fields ‚Üí Document in Phase 1

12. ‚ùì Did I extract HTTP status codes for downstream operations? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Extract downstream HTTP codes ‚Üí Document in Phase 1

13. ‚ùì Did I create request/response JSON examples? (Answer: YES/NO)
   - **REQUIRED:** YES
   - If NO ‚Üí **STOP** ‚Üí Create JSON examples ‚Üí Document in Phase 1

**IF ANY ANSWER IS NO ‚Üí STOP ‚Üí COMPLETE THAT STEP ‚Üí THEN PROCEED TO PHASE 2**

**VALIDATION:** Phase 1 document MUST contain:
- Section 15 (Map Analysis) with complete field mapping analysis
- Section 16 (HTTP Status Codes and Return Path Responses) with all return paths documented
- Section 17 (Request/Response JSON Examples) with actual JSON examples
Before proceeding to Phase 2.

---

---

## üõë POST-PHASE 2: README.md GENERATION (MANDATORY - FINAL STEP)

**üö® CRITICAL:** README.md MUST be generated as the FINAL step of Phase 2, AFTER all code is complete and committed.

**Purpose:** Document the implemented System Layer for Process Layer consumers and operations teams.

**Source of Truth:** BOOMI_EXTRACTION_PHASE1.md Section 13 (Sequence Diagram)

**When:** After all code files are implemented, tested, and committed.

---

### README.md STRUCTURE (19 MANDATORY SECTIONS)

**Section Order (NON-NEGOTIABLE):**

1. **Title & Metadata** - SOR, Integration Type, Authentication, Framework
2. **Overview** - Brief description, key operations list
3. **Architecture** - API-Led layers diagram (Process ‚Üí System ‚Üí SOR)
4. **Sequence Diagrams** - ONE per Azure Function (CRITICAL - see below)
5. **Folder Structure** - Tree view with comments
6. **Azure Functions Exposed** - Detailed API docs per function
7. **Authentication** - Flow, benefits (if applicable)
8. **Configuration** - AppConfigs, KeyVault
9. **Deployment** - Environment files, CI/CD, Azure resources
10. **Process Layer Integration** - Key patterns, workflows
11. **Error Handling Strategy** - Operation classification (CRITICAL - see below)
12. **Error Handling** - Exception types, error codes
13. **Performance** - Timing tracking, example breakdown
14. **Development** - Prerequisites, build, run, test
15. **Dependencies** - Framework projects, NuGet packages
16. **Monitoring** - Application Insights, Live Metrics
17. **Future Enhancements** - Based on TODO placeholders
18. **Support** - Documentation links
19. **Version & Status** - Version, date, status

---

### SECTION 4: SEQUENCE DIAGRAMS (CRITICAL - MOST IMPORTANT)

**üö® MANDATORY REQUIREMENTS:**

**Create ONE sequence diagram per Azure Function showing:**

1. **Complete Component Flow:**
```
Process Layer
  ‚Üì
[Function]API
  ‚Üì
[Middleware] (if auth)
  ‚Üì
I[Domain]Mgmt (Service Interface)
  ‚Üì
[Domain]MgmtService
  ‚Üì
[Operation]Handler
  ‚Üì
[ALL Atomic Handlers with details]
  ‚Üì
Response to Process Layer
```

2. **Operation Classification (MANDATORY for EACH atomic handler):**

**Classification Values:**
- `(AUTHENTICATION)` - Auth operations (throw on failure)
- `(BEST-EFFORT LOOKUP)` - Enrichment operations (continue on failure)
- `(MAIN OPERATION)` - Primary operations (throw on failure)
- `(CONDITIONAL)` - Optional operations (continue on failure)
- `(CLEANUP)` - Cleanup operations (continue on failure)

3. **Error Handling Specification (MANDATORY for EACH atomic handler):**

**Format:**
```
‚îú‚îÄ‚Üí STEP N: [AtomicHandlerName] (OPERATION_CLASSIFICATION)
|    ‚îî‚îÄ‚Üí [Protocol]: [Operation] ([parameters])
|    ‚îî‚îÄ‚Üí Response: [fields]
|    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí [Log warning/Throw exception], [set empty/stop], [CONTINUE/STOP]
|    ‚îî‚îÄ‚Üí Result: [variables] (populated or empty / throws exception)
```

**Example (BEST-EFFORT):**
```
‚îú‚îÄ‚Üí STEP 1: GetLocationsByDtoAtomicHandler (BEST-EFFORT LOOKUP)
|    ‚îî‚îÄ‚Üí SOAP: GetLocationsByDto (sessionId + propertyName + unitCode)
|    ‚îî‚îÄ‚Üí Response: LocationId, BuildingId
|    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Log warning, set empty values, CONTINUE
|    ‚îî‚îÄ‚Üí Result: locationId, buildingId (populated or empty)
```

**Example (MAIN OPERATION):**
```
‚îú‚îÄ‚Üí STEP 3: CreateBreakdownTaskAtomicHandler (MAIN OPERATION)
|    ‚îî‚îÄ‚Üí SOAP: CreateBreakdownTask (sessionId + all fields + lookup IDs)
|    ‚îî‚îÄ‚Üí Uses: locationId, buildingId (may be empty if lookups failed)
|    ‚îî‚îÄ‚Üí Response: BreakdownTaskId, Status
|    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Throw exception (main operation must succeed)
|    ‚îî‚îÄ‚Üí Result: breakdownTaskId (throws exception on failure)
```

4. **Boomi Pattern Reference (MANDATORY):**

**At top of each sequence diagram:**
```markdown
**üìã BASED ON:** BOOMI_EXTRACTION_PHASE1.md Section 13 (Sequence Diagram)  
**Error Handling:** Derived from Boomi [pattern_name] ([shape_references])
```

**Examples:**
- "Derived from Boomi branch convergence pattern (shape6)"
- "Derived from Boomi check-before-create pattern (decision shape55)"

---

### SECTION 11: ERROR HANDLING STRATEGY (CRITICAL)

**üö® MANDATORY SECTION - MUST ACCURATELY REFLECT BOOMI BEHAVIOR**

**Format:**
```markdown
## ERROR HANDLING STRATEGY

### Operation Classification

**MUST-SUCCEED Operations (Throw on Failure):**

| Operation | Reason | Action on Failure |
|---|---|---|
| [Op1] | [Why must succeed] | Throw exception ([where]) |

**BEST-EFFORT Operations (Continue on Failure):**

| Operation | Reason | Action on Failure |
|---|---|---|
| [Op1] | [Why best-effort] | Log warning, set empty, continue |

### Rationale: [Boomi Pattern Name]

**From Boomi Analysis:**
- [Reference to Phase 1 section]
- [Key finding with shape numbers]
- [Convergence/decision behavior]

**Azure Implementation:**
```csharp
// [Pattern description]
[Code example - 10-15 lines showing the pattern]
```

**Benefits:**
- ‚úÖ [Benefit 1]
- ‚úÖ [Benefit 2]
```

---

### ALGORITHM: DETERMINE ERROR HANDLING FROM BOOMI (MANDATORY)

**Use this algorithm to classify operations:**

```
FOR EACH atomic handler operation:
    
    Step 1: Check for Decision Shapes After Operation
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    Search Phase 1 Section 10 (Decision Analysis)
    
    IF decision shape exists after this operation:
        IF decision checks status code (meta.base.applicationstatuscode):
            ‚îî‚îÄ‚Üí Operation has explicit error handling
            ‚îî‚îÄ‚Üí Trace TRUE path (success) and FALSE path (error)
            ‚îî‚îÄ‚Üí Determine classification from path behavior
        ELSE:
            ‚îî‚îÄ‚Üí Go to Step 2
    ELSE:
        ‚îî‚îÄ‚Üí No decision shape found
        ‚îî‚îÄ‚Üí Go to Step 2
    
    Step 2: Check Branch Convergence
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    Search Phase 1 Section 11 (Branch Analysis)
    
    IF operation is in branch path:
        IF branch paths converge at stop shape (continue=true):
            ‚îî‚îÄ‚Üí Operation continues to convergence regardless of result
            ‚îî‚îÄ‚Üí Classification: BEST-EFFORT LOOKUP
            ‚îî‚îÄ‚Üí Error Handling: Log warning, set empty, CONTINUE
            ‚îî‚îÄ‚Üí Document: "Derived from Boomi branch convergence pattern (shape[N])"
        ELSE:
            ‚îî‚îÄ‚Üí Go to Step 3
    ELSE:
        ‚îî‚îÄ‚Üí Not in branch path
        ‚îî‚îÄ‚Üí Go to Step 3
    
    Step 3: Check Operation Type
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    Based on operation purpose and Phase 1 analysis:
    
    IF operation is authentication (Login, GetToken):
        ‚îî‚îÄ‚Üí Classification: AUTHENTICATION
        ‚îî‚îÄ‚Üí Error Handling: Throw exception (required for all operations)
        ‚îî‚îÄ‚Üí Reason: "Required for all downstream operations"
    
    ELIF operation is main business operation (Create, Update, Delete):
        ‚îî‚îÄ‚Üí Classification: MAIN OPERATION
        ‚îî‚îÄ‚Üí Error Handling: Throw exception (operation must succeed)
        ‚îî‚îÄ‚Üí Reason: "Primary business operation"
    
    ELIF operation is cleanup (Logout, CloseConnection):
        ‚îî‚îÄ‚Üí Classification: CLEANUP
        ‚îî‚îÄ‚Üí Error Handling: Log error, CONTINUE (non-critical)
        ‚îî‚îÄ‚Üí Reason: "Cleanup only, non-critical"
    
    ELIF operation is conditional/optional:
        ‚îî‚îÄ‚Üí Classification: CONDITIONAL
        ‚îî‚îÄ‚Üí Error Handling: Log warning, CONTINUE (non-critical)
        ‚îî‚îÄ‚Üí Reason: "Optional operation, main operation already succeeded"
    
    ELSE (lookup, enrichment, query):
        ‚îî‚îÄ‚Üí Classification: BEST-EFFORT LOOKUP
        ‚îî‚îÄ‚Üí Error Handling: Log warning, set empty, CONTINUE
        ‚îî‚îÄ‚Üí Reason: "Enrichment operation, not required for main operation"
```

**Output for Each Operation:**
- Classification: [AUTHENTICATION / BEST-EFFORT LOOKUP / MAIN OPERATION / CONDITIONAL / CLEANUP]
- Error Handling: [Throw exception / Log warning, set empty, continue / Log error, continue]
- Reason: [Why this classification]
- Boomi Reference: [Shape numbers, pattern name]

---

### VALIDATION CHECKLIST FOR README.md (MANDATORY)

**Before finalizing README.md, verify:**

**Phase 1 Verification:**
- [ ] BOOMI_EXTRACTION_PHASE1.md Section 13 (Sequence Diagram) complete
- [ ] Section 10 (Decision Analysis) complete
- [ ] Section 11 (Branch Analysis) complete
- [ ] Section 6 (HTTP Status Codes) complete
- [ ] Error handling behavior verified from Boomi JSON

**Sequence Diagram Completeness:**
- [ ] ALL Azure Functions have sequence diagrams
- [ ] ALL atomic handlers shown (not skipped)
- [ ] EACH atomic handler has operation classification
- [ ] EACH atomic handler has error handling specification
- [ ] EACH atomic handler has result specification
- [ ] Conditional logic shown with IF/ELSE
- [ ] Boomi pattern references included

**Error Handling Strategy:**
- [ ] Operation classification table complete
- [ ] ALL operations classified (MUST-SUCCEED vs BEST-EFFORT)
- [ ] Rationale references Boomi analysis (shape numbers)
- [ ] Code example shows actual implementation
- [ ] Classification verified from Boomi JSON (not assumed)

**Content Accuracy:**
- [ ] Request/response examples use actual field names (from Phase 1)
- [ ] Folder structure matches actual project structure
- [ ] Configuration examples show actual config keys
- [ ] Error codes match ErrorConstants.cs
- [ ] All 19 sections present

**Cross-Validation:**
- [ ] Sequence diagrams match Phase 1 Section 13
- [ ] Error handling matches code implementation
- [ ] Operation classification matches Boomi behavior
- [ ] No assumptions made (all verified from JSON)

---

### COMMON MISTAKES TO AVOID

**Mistake 1: Creating README Before Code**
- ‚ùå README created during code generation
- ‚úÖ README created AFTER code is complete and committed

**Mistake 2: Generic Sequence Diagrams**
- ‚ùå Missing atomic handlers, no error handling, no classification
- ‚úÖ Complete flow with classification and error handling for EACH step

**Mistake 3: Assuming Error Handling**
- ‚ùå Assume all operations throw exceptions on failure
- ‚úÖ Verify from Boomi JSON (check for decision shapes, convergence)

**Mistake 4: Missing Operation Classification**
- ‚ùå No classification specified for atomic handlers
- ‚úÖ BEST-EFFORT LOOKUP / MAIN OPERATION / etc. for EACH handler

**Mistake 5: Not Referencing Boomi Analysis**
- ‚ùå Generic error handling explanation
- ‚úÖ Reference shape numbers, patterns, convergence points from Phase 1

---

### EXAMPLE: CORRECT SEQUENCE DIAGRAM WITH ERROR HANDLING

```markdown
### CreateBreakdownTask Operation

**üìã BASED ON:** BOOMI_EXTRACTION_PHASE1.md Section 13 (Sequence Diagram)  
**Error Handling:** Derived from Boomi branch convergence pattern (shape6) and conditional execution pattern (shape31)

```
Process Layer
     |
     | POST /cafm/breakdown-tasks/create
     | { "serviceRequestNumber": "EQ-2025-001", ... }
     ‚Üì
CreateBreakdownTaskAPI (Function)
     |
     | [CustomAuthentication] attribute triggers middleware
     ‚Üì
CustomAuthenticationMiddleware
     |
     ‚îú‚îÄ‚Üí AuthenticateAtomicHandler (AUTHENTICATION)
     |    ‚îî‚îÄ‚Üí SOAP: Authenticate (username/password from KeyVault)
     |    ‚îî‚îÄ‚Üí Response: SessionId
     |    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Throw exception (required for all operations)
     |    ‚îî‚îÄ‚Üí Result: sessionId (throws exception on failure)
     |    ‚îî‚îÄ‚Üí Store in RequestContext (AsyncLocal)
     |
     ‚Üì Continue to function
     |
IBreakdownTaskMgmt (Service Interface)
     ‚Üì
BreakdownTaskMgmtService
     ‚Üì
CreateBreakdownTaskHandler
     |
     ‚îú‚îÄ‚Üí Read SessionId from RequestContext
     |
     ‚îú‚îÄ‚Üí STEP 1: GetLocationsByDtoAtomicHandler (BEST-EFFORT LOOKUP)
     |    ‚îî‚îÄ‚Üí SOAP: GetLocationsByDto (sessionId + propertyName + unitCode)
     |    ‚îî‚îÄ‚Üí Response: LocationId, BuildingId
     |    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Log warning, set empty values, CONTINUE
     |    ‚îî‚îÄ‚Üí Result: locationId, buildingId (populated or empty)
     |    ‚îî‚îÄ‚Üí Boomi: Branch path 3 (shape23-24-25) converges at shape6 (no decision checks)
     |
     ‚îú‚îÄ‚Üí STEP 2: GetInstructionSetsByDtoAtomicHandler (BEST-EFFORT LOOKUP)
     |    ‚îî‚îÄ‚Üí SOAP: GetInstructionSetsByDto (sessionId + categoryName + subCategory)
     |    ‚îî‚îÄ‚Üí Response: InstructionId
     |    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Log warning, set empty value, CONTINUE
     |    ‚îî‚îÄ‚Üí Result: instructionId (populated or empty)
     |    ‚îî‚îÄ‚Üí Boomi: Branch path 4 (shape26-27-28) converges at shape6 (no decision checks)
     |
     ‚îú‚îÄ‚Üí STEP 3: CreateBreakdownTaskAtomicHandler (MAIN OPERATION)
     |    ‚îî‚îÄ‚Üí Format dates (ScheduledDateUtc, RaisedDateUtc)
     |    ‚îî‚îÄ‚Üí SOAP: CreateBreakdownTask (sessionId + all fields + lookup IDs)
     |    ‚îî‚îÄ‚Üí Uses: locationId, buildingId, instructionId (may be empty if lookups failed)
     |    ‚îî‚îÄ‚Üí Response: BreakdownTaskId, Status
     |    ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Throw exception (main operation must succeed)
     |    ‚îî‚îÄ‚Üí Result: breakdownTaskId (throws exception on failure)
     |    ‚îî‚îÄ‚Üí Boomi: Main operation (shape11) with decision shape12 checking status
     |
     ‚îú‚îÄ‚Üí STEP 4: Conditional Event Linking
     |    ‚îî‚îÄ‚Üí IF ticketDetails.recurrence == "Y":
     |         ‚îî‚îÄ‚Üí CreateEventAtomicHandler (CONDITIONAL)
     |              ‚îî‚îÄ‚Üí SOAP: CreateEvent (sessionId + breakdownTaskId)
     |              ‚îî‚îÄ‚Üí Response: EventId
     |              ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Log warning, CONTINUE (task already created)
     |              ‚îî‚îÄ‚Üí Result: eventId (may be empty if failed)
     |              ‚îî‚îÄ‚Üí Boomi: Conditional execution (decision shape31)
     |    ‚îî‚îÄ‚Üí ELSE:
     |         ‚îî‚îÄ‚Üí Skip event creation
     |         ‚îî‚îÄ‚Üí Boomi: Early exit path (shape31 TRUE path)
     |
     ‚îú‚îÄ‚Üí Map ApiResDTO ‚Üí CreateBreakdownTaskResDTO
     ‚îî‚îÄ‚Üí Return BaseResponseDTO
     |
     ‚Üì After function completes
     |
CustomAuthenticationMiddleware (finally block)
     |
     ‚îî‚îÄ‚Üí LogoutAtomicHandler (CLEANUP)
          ‚îî‚îÄ‚Üí SOAP: Logout (sessionId)
          ‚îî‚îÄ‚Üí Error Handling: If fails ‚Üí Log error, CONTINUE (cleanup only)
          ‚îî‚îÄ‚Üí Clear RequestContext
     |
     ‚Üì
Response to Process Layer
{ "breakdownTaskId": "CAFM-2025-12345", "status": "Success" }
```
```

**Key Elements:**
- ‚úÖ Shows ALL atomic handlers (not skipped)
- ‚úÖ Each handler has classification (BEST-EFFORT / MAIN OPERATION / etc.)
- ‚úÖ Each handler has error handling (throw vs continue)
- ‚úÖ Each handler has result (populated or empty / throws)
- ‚úÖ Conditional logic with IF/ELSE
- ‚úÖ Boomi references (shape numbers, patterns)

---

### SECTION 11: ERROR HANDLING STRATEGY (CRITICAL)

**MANDATORY TABLE:**

```markdown
## ERROR HANDLING STRATEGY

### Operation Classification

**MUST-SUCCEED Operations (Throw on Failure):**

| Operation | Reason | Action on Failure |
|---|---|---|
| Login/Authenticate | Required for all operations | Throw exception (middleware) |
| [MainOperation] | Primary business operation | Throw exception (handler) |

**BEST-EFFORT Operations (Continue on Failure):**

| Operation | Reason | Action on Failure |
|---|---|---|
| [LookupOp1] | Enrichment lookup | Log warning, set empty, continue |
| [LookupOp2] | Enrichment lookup | Log warning, set empty, continue |
| [ConditionalOp] | Optional operation | Log warning, continue |
| Logout | Cleanup only | Log error, continue |

### Rationale: [Boomi Pattern Name]

**From Boomi Analysis:**
- [Reference Phase 1 section and shape numbers]
- [Key finding about convergence or decision shapes]
- [Explanation of why operations continue on failure]

**Azure Implementation:**
```csharp
// [Pattern description]
HttpResponseSnapshot response = await GetLookupData(...);

if (!response.IsSuccessStatusCode) {
    _logger.Warn("Lookup failed - Continuing with empty values");
    lookupId = string.Empty; // Continue with empty
} else {
    lookupId = ExtractFromResponse(...); // Extract if success
}

// Continue to next operation (don't throw)
await MainOperation(..., lookupId, ...); // May be empty
```

**Benefits:**
- ‚úÖ Resilient: Lookup failures don't stop main operation
- ‚úÖ Validation at right place: [SOR] validates required fields
- ‚úÖ Accurate errors: Error from [SOR] (not generic lookup error)
- ‚úÖ Matches Boomi: Same behavior as original process
```

---

### ALGORITHM: DETERMINE OPERATION CLASSIFICATION

**Step 1: Check Decision Shapes (from Phase 1 Section 10)**

```
FOR operation in atomic_handlers:
    decision_shapes = Find decision shapes after operation in Phase 1
    
    IF decision_shapes found AND checks status code:
        ‚îî‚îÄ‚Üí Has explicit error handling
        ‚îî‚îÄ‚Üí Trace TRUE/FALSE paths
        ‚îî‚îÄ‚Üí Classify based on path behavior
    ELSE:
        ‚îî‚îÄ‚Üí No explicit error handling
        ‚îî‚îÄ‚Üí Go to Step 2
```

**Step 2: Check Branch Convergence (from Phase 1 Section 11)**

```
    IF operation is in branch path:
        convergence_point = Find convergence point in Phase 1
        
        IF convergence_point is stop with continue=true:
            ‚îî‚îÄ‚Üí Branch paths converge regardless of results
            ‚îî‚îÄ‚Üí Classification: BEST-EFFORT LOOKUP
            ‚îî‚îÄ‚Üí Error Handling: Log warning, set empty, CONTINUE
            ‚îî‚îÄ‚Üí Reason: "Branch convergence pattern (shape[N])"
        ELSE:
            ‚îî‚îÄ‚Üí Go to Step 3
    ELSE:
        ‚îî‚îÄ‚Üí Not in branch path
        ‚îî‚îÄ‚Üí Go to Step 3
```

**Step 3: Check Operation Type**

```
    IF operation is authentication (Login, GetToken):
        ‚îî‚îÄ‚Üí Classification: AUTHENTICATION
        ‚îî‚îÄ‚Üí Error Handling: Throw exception
        ‚îî‚îÄ‚Üí Reason: "Required for all downstream operations"
    
    ELIF operation is main business operation (Create, Update, Delete):
        ‚îî‚îÄ‚Üí Classification: MAIN OPERATION
        ‚îî‚îÄ‚Üí Error Handling: Throw exception
        ‚îî‚îÄ‚Üí Reason: "Primary business operation"
    
    ELIF operation is cleanup (Logout, CloseConnection):
        ‚îî‚îÄ‚Üí Classification: CLEANUP
        ‚îî‚îÄ‚Üí Error Handling: Log error, CONTINUE
        ‚îî‚îÄ‚Üí Reason: "Cleanup only, non-critical"
    
    ELIF operation is conditional/optional:
        ‚îî‚îÄ‚Üí Classification: CONDITIONAL
        ‚îî‚îÄ‚Üí Error Handling: Log warning, CONTINUE
        ‚îî‚îÄ‚Üí Reason: "Optional operation, main operation already succeeded"
    
    ELSE (lookup, enrichment, query):
        ‚îî‚îÄ‚Üí Classification: BEST-EFFORT LOOKUP
        ‚îî‚îÄ‚Üí Error Handling: Log warning, set empty, CONTINUE
        ‚îî‚îÄ‚Üí Reason: "Enrichment operation, not required for main operation"
```

**Output:**
- Classification for EACH operation
- Error handling strategy for EACH operation
- Reason/rationale for EACH classification
- Boomi reference (shape numbers, patterns)

---

### README.md GENERATION CHECKLIST

**Before generating README.md:**

- [ ] Phase 1 document complete and verified
- [ ] All code files implemented and committed
- [ ] Error handling verified from Boomi JSON
- [ ] Operation classification determined for ALL operations
- [ ] Algorithm applied to classify each operation

**During README.md generation:**

- [ ] Use Phase 1 Section 13 as blueprint for sequence diagrams
- [ ] Apply operation classification to EACH atomic handler
- [ ] Show error handling for EACH atomic handler
- [ ] Reference Boomi patterns (shape numbers, convergence, decisions)
- [ ] Include ALL 19 sections
- [ ] Use realistic examples (actual field names from Phase 1)

**After README.md generation:**

- [ ] Validate sequence diagrams match Phase 1
- [ ] Validate error handling matches code implementation
- [ ] Validate operation classification verified from Boomi
- [ ] All validation checklist items complete
- [ ] Commit README.md with descriptive message

---

**Document Version:** 2.4  
**Purpose:** Prescriptive guide for extracting execution sequence from ANY Boomi process  
**Key Changes:** 
- Version 2.0: Made rules explicit, mandatory, and non-negotiable
- Version 2.1: Added mandatory Input/Output Structure Analysis (Contract Verification)
- Version 2.2: Added mandatory Map Analysis (Step 1d) - Critical for SOAP envelope field name verification
- Version 2.3: Added mandatory HTTP Status Codes and Return Path Responses (Step 1e) - Critical for error handling and response mapping; Added Request/Response JSON Examples section
- Version 2.4: Added README.md Generation rules (Post-Phase 2) - Critical for documenting error handling behavior with operation classification system
